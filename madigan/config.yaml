agent_config:
  action_atoms: 3
  batch_size: 34
  discount: 0.999
  discrete_action_atoms: 3
  double_dqn: true
  dueling: true
  episode_length: 1024
  eps: 1.0
  eps_decay: 0.999999
  eps_min: 0.1
  expl_noise_sd: 0.01
  greedy_eps_testing: 0.0
  iqn: true
  k_huber: 1
  nTau1: 32
  nTau2: 8
  nstep_return: 5
  nsteps: 1000000
  replay_min_size: 50000
  replay_size: 100000
  reward_clip: &id001 !!python/tuple
  - -1.0
  - 1.0
  tau_embed_size: 64
  tau_soft_update: 0.0001
  train_freq: 4
  type: DQN
  unit_size_proportion_avM: 0.1
  proximal_portfolio_penalty: .5
  transaction_thresh: 0.02
agent_type: DQNReverser
assets:
- sine1
basepath: /media/hemu/Data/madigan/experiments/
data_source_config:
  trend_prob:
  - .01
  min_period:
  - 75
  max_period:
  - 125
  noise:
  - .0
  dY:
  - 0.01
  start:
  - 5.0
data_source_type: SimpleTrend
discrete_action_atoms: 3
discrete_actions: true
env_type: Synth
experiment_id: DQNReverser_Trend_Roller_trans02_5step_grad_norm_clip_discount.999_abs_norm_port
init_cash: 1000000
log_freq: 10000
lot_unit_value: 10000
maintenance_margin: 0.25
min_tf: 64
model_config:
  action_atoms: 3
  d_model: 1024
  discrete_action_atoms: 3
  discrete_actions: true
  dueling: true
  iqn: true
  lot_unit_value: 10000
  min_tf: 64
  model_class: ConvNet
  critic_model_class: ConvCriticQ
  actor_model_class: ConvPolicyDeterministic
  nTau1: 32
  nTau2: 8
  n_layers: 4
  tau_embed_size: 64
  kernels:
  - 5
  - 5
  channels:
  - 32
  - 32
  strides:
  - 1
  - 1
model_save_freq: 64000
n_assets: 1
optim_config:
  betas: !!python/tuple
  - 0.9
  - 0.999
  eps: 1.0e-08
  lr: 0.001
  lr_actor: 0.0001
  lr_critic: 0.001
  momentum: 0.9
  type: Adam
  weight_decay: 0
parent_id: ''
preprocessor_config:
  preprocessor_type: RollerDiscrete
  window_length: 64
  timeframes:
  - 64
preprocessor_type: RollerDiscrete
required_margin: 1.0
reward_clip: *id001
slippage_abs: 0.0
slippage_rel: 0.0
test_freq: 10000
test_steps: 4096
train_steps: 100000
transaction_cost_abs: 0.0
transaction_cost_rel: 0.02
