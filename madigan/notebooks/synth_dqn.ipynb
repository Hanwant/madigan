{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import math\n",
    "\n",
    "import numba\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from madigan.environments import make_env\n",
    "from madigan.environments.cpp import Broker, Synth, Env as EnvC\n",
    "from madigan.environments.cpp import Assets, RiskInfo, EnvInfoMulti, EnvInfoSingle\n",
    "\n",
    "from madigan.fleet import make_agent\n",
    "\n",
    "from madigan.utils.preprocessor import make_preprocessor as _make_preprocessor\n",
    "from madigan.utils import make_config, State\n",
    "from madigan.utils import ReplayBuffer, SARSD, DiscreteActionSpace\n",
    "from madigan.utils import list_2_dict, reduce_train_metrics\n",
    "\n",
    "\n",
    "from madigan.run.test import test\n",
    "from madigan.utils.plotting import plot_test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'basepath': '/media/hemu/Data/Markets/farm',\n",
       " 'experiment_id': 'SineQ',\n",
       " 'parent_id': '',\n",
       " 'overwrite_exp': False,\n",
       " 'transaction_cost_abs': 0.0,\n",
       " 'transaction_cost_rel': 0.01,\n",
       " 'slippage_abs': 0.0,\n",
       " 'slippage_rel': 0.0,\n",
       " 'env_type': 'Synth',\n",
       " 'data_source_type': 'OU',\n",
       " 'init_cash': 1000000,\n",
       " 'required_margin': 1.0,\n",
       " 'maintenance_margin': 0.25,\n",
       " 'generator_params': {'mean': [10.0],\n",
       "  'theta': [0.15],\n",
       "  'phi': [1.0],\n",
       "  'noise_var': [0.1]},\n",
       " 'assets': ['OU1'],\n",
       " 'lot_unit_value': 100000,\n",
       " 'n_assets': 1,\n",
       " 'discrete_actions': True,\n",
       " 'discrete_action_atoms': 3,\n",
       " 'preprocessor_type': 'WindowedStacker',\n",
       " 'preprocessor_config': {'window_length': 64},\n",
       " 'agent_type': 'DQN',\n",
       " 'agent_config': {'type': 'DQN',\n",
       "  'basepath': '/media/hemu/Data/Markets/farm',\n",
       "  'discrete_action_atoms': 3,\n",
       "  'model_config': {'model_class': 'ConvModel',\n",
       "   'd_model': 256,\n",
       "   'n_layers': 4,\n",
       "   'n_feats': 1,\n",
       "   'action_atoms': 3,\n",
       "   'n_assets': 1,\n",
       "   'min_tf': 64,\n",
       "   'dueling': False,\n",
       "   'iqn': False,\n",
       "   'nTau1': 32,\n",
       "   'nTau2': 32,\n",
       "   'tau_embed_size': 64,\n",
       "   'discrete_actions': True,\n",
       "   'discrete_action_atoms': 3,\n",
       "   'lot_unit_value': 100000},\n",
       "  'optim_config': {'type': 'Adam',\n",
       "   'lr': 0.001,\n",
       "   'lr_critic': 0.001,\n",
       "   'lr_actor': 0.0001,\n",
       "   'eps': 1e-08,\n",
       "   'momentum': 0.9,\n",
       "   'betas': (0.9, 0.999),\n",
       "   'weight_decay': 0},\n",
       "  'double_dqn': True,\n",
       "  'dueling': False,\n",
       "  'iqn': False,\n",
       "  'nTau1': 32,\n",
       "  'nTau2': 32,\n",
       "  'k_huber': 1.0,\n",
       "  'tau_embed_size': 64,\n",
       "  'discount': 0.999,\n",
       "  'nstep_return': 3,\n",
       "  'action_atoms': 3,\n",
       "  'tau_soft_update': 0.0001,\n",
       "  'greedy_eps_testing': 0.0},\n",
       " 'model_config': {'model_class': 'ConvModel',\n",
       "  'd_model': 256,\n",
       "  'n_layers': 4,\n",
       "  'n_feats': 1,\n",
       "  'action_atoms': 3,\n",
       "  'n_assets': 1,\n",
       "  'min_tf': 64,\n",
       "  'dueling': False,\n",
       "  'iqn': False,\n",
       "  'nTau1': 32,\n",
       "  'nTau2': 32,\n",
       "  'tau_embed_size': 64,\n",
       "  'discrete_actions': True,\n",
       "  'discrete_action_atoms': 3,\n",
       "  'lot_unit_value': 100000},\n",
       " 'optim_config': {'type': 'Adam',\n",
       "  'lr': 0.001,\n",
       "  'lr_critic': 0.001,\n",
       "  'lr_actor': 0.0001,\n",
       "  'eps': 1e-08,\n",
       "  'momentum': 0.9,\n",
       "  'betas': (0.9, 0.999),\n",
       "  'weight_decay': 0},\n",
       " 'nsteps': 1000000,\n",
       " 'test_steps': 1000,\n",
       " 'rb_size': 100000,\n",
       " 'episode_length': 1024,\n",
       " 'min_rb_size': 50000,\n",
       " 'train_freq': 4,\n",
       " 'target_update_freq': 12000,\n",
       " 'test_freq': 32000,\n",
       " 'log_freq': 10000,\n",
       " 'model_save_freq': 64000,\n",
       " 'min_tf': 64,\n",
       " 'batch_size': 32,\n",
       " 'nstep_return': 3,\n",
       " 'expl_eps': 1.0,\n",
       " 'expl_eps_min': 0.1,\n",
       " 'expl_eps_decay': 1e-06,\n",
       " 'reward_clip': (-1.0, 1.0)}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "config = make_config(\n",
    "        experiment_id=\"SineQ\",\n",
    "        basepath=\"/media/hemu/Data/Markets/farm\",\n",
    "        overwrite_exp=False,\n",
    "        test_steps=1_000,\n",
    "        nsteps=1_000_000,\n",
    "        transaction_cost_rel=0.01,\n",
    "    \n",
    "        assets=[\"OU1\"],\n",
    "#         data_source_type=\"SineAdder\",\n",
    "#         generator_params={\n",
    "#             'freq':[2.2, 4.1, 1., 3.],\n",
    "#             'mu':[.6, 0.3, 2., 4.2],\n",
    "#             'amp':[.5, 0.2, 0.4, 1.2],\n",
    "#             'phase':[0., 1., 4., 0.],\n",
    "#             'dX':0.01,\n",
    "#             \"noise\": 0.0},\n",
    "        data_source_type=\"OU\",\n",
    "        generator_params=dict(\n",
    "            mean=[10.],\n",
    "            theta=[.15],\n",
    "            phi = [1.],\n",
    "            noise_var = [.1],\n",
    "            \n",
    "        ),\n",
    "\n",
    "        preprocessor_type=\"WindowedStacker\",\n",
    "        window_length=64,\n",
    "    \n",
    "        agent_type = \"DQN\",\n",
    "        discrete_actions=True,\n",
    "        discrete_action_atoms=3,\n",
    "        double_dqn=True,\n",
    "        nstep_return = 3,\n",
    "        target_update_freq=12000,\n",
    "        rb_size=100_000,\n",
    "        min_rb_size=50_000,\n",
    "        batch_size=32,\n",
    "        discount = 0.999,\n",
    "        lot_unit_value=100_000,\n",
    "    \n",
    "    \n",
    "        model_class=\"ConvModel\",\n",
    "        lr=1e-3,\n",
    "\n",
    "    )\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.58856193,  1.59213114,  1.15548726,  1.01404463,  0.09705897,\n",
       "        -0.7442525 , -1.19690215, -1.08128126, -0.6942728 ,  0.00292756]),\n",
       " array([ 1.,  1.,  1.,  1.,  1., -1., -1., -1., -1.,  1.]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@numba.njit\n",
    "def ternarize_array(arr):\n",
    "    out = np.empty_like(arr)\n",
    "    out[arr<0.] = -1.\n",
    "    out[arr==0.] = 0.\n",
    "    out[arr>0.] = 1.\n",
    "    return out\n",
    "# test\n",
    "ara = np.random.randn(10)\n",
    "out = ternarize_array(ara)\n",
    "ara, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.6223596 ],\n",
       "        [ 0.21314044],\n",
       "        [ 1.26770486],\n",
       "        [-0.29052271],\n",
       "        [-0.1510905 ],\n",
       "        [ 1.18933241],\n",
       "        [ 0.34503476],\n",
       "        [ 0.62640746],\n",
       "        [-0.00484524],\n",
       "        [ 0.16975866]]),\n",
       " array([[-1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [-1.],\n",
       "        [-1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [-1.],\n",
       "        [ 1.]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @numba.vectorize([numba.int32(numba.int32),\n",
    "#                   numba.int64(numba.int64),\n",
    "#                   numba.float32(numba.float32),\n",
    "#                   numba.float64(numba.float64)])\n",
    "\n",
    "@numba.vectorize([numba.float32(numba.float32),\n",
    "                  numba.float64(numba.float64)])\n",
    "def ternarize_array(val):\n",
    "    if val < 0:\n",
    "        out = -1.\n",
    "    elif val > 0.:\n",
    "        out = 1.\n",
    "    else:\n",
    "        out = 0.\n",
    "    return out\n",
    "# test\n",
    "ara = np.random.randn(10, 1)\n",
    "out = ternarize_array(ara)\n",
    "ara, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     3,
     13
    ]
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class BrokerResponse:\n",
    "    event: str\n",
    "    timestamp: int\n",
    "    transPrice: float\n",
    "    transUnits: float\n",
    "    transCost: float\n",
    "    riskInfo: object\n",
    "    marginCall: bool\n",
    "\n",
    "@dataclass\n",
    "class EnvInfo:\n",
    "    brokerResponse: BrokerResponse\n",
    "    exiting: bool\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class EnvTernary(EnvC):\n",
    "    def step(self, actions: np.ndarray = None):\n",
    "        \"\"\"\n",
    "        If actions is None, no transaction is attempted and dataSource is iterated to\n",
    "        get new prices\n",
    "        If actions is passed, a transaction/s is attempted. Can only Reverse Positions, not add to \n",
    "        or close.\n",
    "        Hence EnvBinary.\n",
    "        \"\"\"\n",
    "\n",
    "        if actions is None: # no transaction\n",
    "            prevEq = self.portfolio.equity\n",
    "            newPrices = self.dataSource.getData()\n",
    "            newEq = self.portfolio.equity\n",
    "            reward = (newEq-prevEq) / prevEq\n",
    "            risk = self.portfolio.checkRisk()\n",
    "            done = False if risk == RiskInfo.green else True\n",
    "\n",
    "            return (State(newPrices, np.array(self.ledgerNormed, copy=True),\n",
    "                          self.dataSource.currentTime),\n",
    "                    reward, done, EnvInfo(BrokerResponse(\"\", 0, 0., 0., 0., \n",
    "                                                             risk, done), False))\n",
    "        else:\n",
    "            if not isinstance(actions, np.ndarray):\n",
    "                raise TypeError(\"action must be an np array\")\n",
    "\n",
    "            prevEq = self.portfolio.equity\n",
    "            newPrices = self.dataSource.getData()\n",
    "            newEq = self.portfolio.equity\n",
    "            reward = newEq / prevEq \n",
    "            reward = math.log(max(reward, 0.3))\n",
    "\n",
    "            ledger_ternary = self.ledgerTernary\n",
    "            actions_ternary = actions - 1\n",
    "#             actions_ternary[ledger_ternary == actions_ternary] = 0.\n",
    "            units = (0.2*self.availableMargin) / self.currentPrices\n",
    "            transactions = actions_ternary * units\n",
    "\n",
    "#             exiting = False\n",
    "            assets = np.where(transactions!=0.)[0]\n",
    "            for i, asset in enumerate(assets): # implicit if len(assets)\n",
    "                reward -= self.transaction_cost_rel\n",
    "#                 if self.ledger[i] != 0:\n",
    "#                     exiting = True\n",
    "#                     self.broker.close(int(asset))\n",
    "                    \n",
    "            broker_response_multi = self.broker.handleTransaction(transactions)\n",
    "            \n",
    "            done = False\n",
    "            if broker_response_multi.marginCall:\n",
    "                done=True\n",
    "            for _risk in broker_response_multi.riskInfo:\n",
    "                if _risk != RiskInfo.green:\n",
    "                    done = True\n",
    "#             if exiting:\n",
    "#                 done = True\n",
    "            if self.equity < 0.1 * self.portfolio.initCash:\n",
    "                done = True\n",
    "                print('equity: ', self.equity)\n",
    "\n",
    "            return (State(newPrices, np.array(self.ledgerNormed, copy=True),\n",
    "                          self.dataSource.currentTime),\n",
    "                    reward, done, EnvInfo(broker_response_multi, 0.))\n",
    "\n",
    "    @property\n",
    "    def ledgerTernary(self):\n",
    "        ara = np.array(self.ledger, copy=True)\n",
    "        return ternarize_array(ara)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# def make_env(config):\n",
    "#     assets = Assets(config.assets)\n",
    "#     env = EnvTernary(config.data_source_type, assets, config.init_cash, config)\n",
    "#     env.lot_unit = config.lot_unit_value\n",
    "#     env.action_atoms = config.discrete_action_atoms\n",
    "#     env.transaction_cost_rel = config.transaction_cost_rel\n",
    "# #     env.setTransactionCost\n",
    "#     return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: 0.0\n",
      "reward: 0.0008633439421742767\n",
      "[9.98780342] 1000000.0 1000000.0 [0.] 1000000.0\n"
     ]
    }
   ],
   "source": [
    "env = make_env(config)\n",
    "srdi = env.step(np.array([10000]))\n",
    "print('reward:', srdi[1])\n",
    "print('reward:', env.step()[1])\n",
    "env.step(np.array([0]))\n",
    "env.reset()\n",
    "print(env.currentPrices, env.cash, env.equity, env.ledger, env.availableMargin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([988.10511039])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srdi[3].brokerResponse.transactionCost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import sklearn.preprocessing\n",
    "\n",
    "class Preprocessor:\n",
    "    def __init__(self, window_len):\n",
    "        self.k = window_len\n",
    "        self.min_tf = self.k\n",
    "        self.price_buffer = deque(maxlen=self.k)\n",
    "        self.portfolio_buffer = deque(maxlen=self.k)\n",
    "        self.time_buffer = deque(maxlen=self.k)\n",
    "        self.feature_output_size = 12\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.price_buffer)\n",
    "\n",
    "    def stream_srdi(self, srdi):\n",
    "        self.price_buffer.append(srdi[0].price)\n",
    "        self.portfolio_buffer.append(srdi[0].portfolio)\n",
    "        self.time_buffer.append(srdi[0].timestamp)\n",
    "\n",
    "    def stream_state(self, state):\n",
    "        self.price_buffer.append(np.array(state.price, copy=True))\n",
    "        self.portfolio_buffer.append(np.array(state.portfolio, copy=True))\n",
    "        self.time_buffer.append(np.array(state.timestamp, copy=True))\n",
    "\n",
    "    def stream(self, data):\n",
    "        if isinstance(data, tuple): # assume srdi\n",
    "            self.stream_srdi(data)\n",
    "        elif isinstance(data, (StateA, State)):\n",
    "            self.stream_state(data)\n",
    "\n",
    "    def current_data(self):\n",
    "        prices = np.array(self.price_buffer, copy=True)\n",
    "        prices = sklearn.preprocessing.minmax_scale(prices)\n",
    "        features = np.empty(self.feature_output_size)\n",
    "        for i, window in enumerate([3, 5, 7, 11]):\n",
    "            features[i] = np.mean(prices[-window:])\n",
    "            features[i+4] = np.var(prices[-window:])\n",
    "        features[8] = prices.min()\n",
    "        features[9] = prices.max()\n",
    "        features[10] = prices[0]\n",
    "        features[11] = prices[-1]\n",
    "        return State(features.reshape(-1, 1) ,\n",
    "                     self.portfolio_buffer[-1],\n",
    "                     self.time_buffer[-1])\n",
    "\n",
    "    def initialize_history(self, env):\n",
    "        while len(self) < self.k:\n",
    "            _state, reward, done, info = env.step()\n",
    "            self.stream_state(_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_preprocessor(config):\n",
    "    if config.preprocessor_type == \"Custom\":\n",
    "        return Preprocessor(config.preprocessor_config.window_length)\n",
    "    return _make_preprocessor(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efc6c81ae50>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.pylabtools import figsize\n",
    "figsize(8, 6)\n",
    "\n",
    "preprocessor = make_preprocessor(config)\n",
    "env.currentPrices\n",
    "preprocessor.initialize_history(env)\n",
    "plt.plot(preprocessor.current_data().price)\n",
    "# env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from madigan.utils import DiscreteRangeSpace, DiscreteActionSpace\n",
    "\n",
    "class AgentLM:\n",
    "    def __init__(self, config, feature_input_size, env, device=None):\n",
    "        self.device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self._env = env\n",
    "        \n",
    "        self.action_atoms = config.discrete_action_atoms\n",
    "        self.lot_unit_value = config.lot_unit_value\n",
    "        actions = [self.lot_unit_value*action - self.action_atoms//2 for action in range(self.action_atoms)]\n",
    "        probs = [1/len(actions) for i in actions]\n",
    "#         self._action_space = DiscreteActionSpace(actions, probs, len(config.assets))\n",
    "#         self._action_space = DiscreteRangeSpace((0, 2), len(config.assets))\n",
    "#         input_size = config.preprocessor_config.window_length + len(config.assets)\n",
    "        input_size = feature_input_size + len(config.assets)\n",
    "        self.model_b = nn.Linear(input_size, self.action_atoms).to(device).float()\n",
    "        self.model_t = nn.Linear(input_size, self.action_atoms).to(device).float()\n",
    "        \n",
    "        self.dueling = config.agent_config.model_config.dueling\n",
    "        self.double_dqn = config.agent_config.double_dqn\n",
    "        self.discount = config.agent_config.discount\n",
    "        \n",
    "        self.opt = torch.optim.Adam(self.model_b.parameters(), lr=config.agent_config.optim_config.lr)\n",
    "        \n",
    "        self.tau_soft_update = config.agent_config.tau_soft_update\n",
    "        self.config = config\n",
    "        \n",
    "    @property\n",
    "    def env(self):\n",
    "        return self._env\n",
    "    \n",
    "    @property\n",
    "    def action_space(self):\n",
    "        units = 0.05 * self.env.availableMargin / self.env.currentPrices\n",
    "        units *= np.array([-1., 0., 1.])\n",
    "        return DiscreteActionSpace(units, probs=[])\n",
    "        actions = np.random.choice([-1., 0., 1.], len(units))\n",
    "        actions *= units\n",
    "        return self._action_space\n",
    "    \n",
    "    def prep_state(self, x):\n",
    "        price = x.price[None, ..., 0]\n",
    "        x = np.concatenate([price, x.portfolio[None, ...]], axis=-1)\n",
    "        return torch.from_numpy(x).float().to(self.device)\n",
    "    \n",
    "    def get_qvals(self, x, target=False):\n",
    "        x = self.prep_state(x)\n",
    "        if target:\n",
    "            qvals = self.model_t(x)\n",
    "        else:\n",
    "            qvals = self.model_b(x)\n",
    "        return qvals.detach()\n",
    "    \n",
    "    def action_to_transaction(self, actions):\n",
    "        units = 0.1 * self.env.availableMargin / self.env.currentPrices\n",
    "        actions_ternary = (actions - (self.action_atoms // 2)).cpu().numpy()\n",
    "        return units * actions_ternary\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def __call__(self, x, target=False):\n",
    "        qvals = self.get_qvals(x, target=target)\n",
    "        actions = qvals.max(-1)[1]\n",
    "        return self.action_to_transaction(actions)\n",
    "        \n",
    "    def prep_sarsd(self, sarsd):\n",
    "        state = State(\n",
    "            price = torch.as_tensor(sarsd.state.price[..., 0], \n",
    "                                    dtype=torch.float32).to(self.device),\n",
    "            portfolio = torch.as_tensor(sarsd.state.portfolio, \n",
    "                                        dtype=torch.float32).to(self.device),\n",
    "            timestamp = sarsd.state.timestamp\n",
    "        )\n",
    "#         action = np.rint(sarsd.action // self.lot_unit_value) + self.action_atoms//2\n",
    "        action = ternarize_array(sarsd.action) + self.action_atoms // 2\n",
    "        action = torch.as_tensor(action, dtype=torch.long, device=self.device)[..., 0]\n",
    "        reward = torch.as_tensor(sarsd.reward, dtype=torch.float32, device=self.device)\n",
    "        next_state = State(\n",
    "            price = torch.as_tensor(sarsd.next_state.price[..., 0], \n",
    "                                    dtype=torch.float32, device=self.device),\n",
    "            portfolio = torch.as_tensor(sarsd.next_state.portfolio, \n",
    "                                        dtype=torch.float32, device=self.device),\n",
    "            timestamp = sarsd.next_state.timestamp\n",
    "        )\n",
    "        done = torch.as_tensor(sarsd.done, dtype=torch.bool, device=self.device)\n",
    "        state = torch.cat([state.price, state.portfolio], dim=-1)\n",
    "        next_state = torch.cat([next_state.price, next_state.portfolio], dim=-1)\n",
    "        return state, action, reward, next_state, done\n",
    "    \n",
    "    def loss_fn(self, Qt, Gt):\n",
    "        return F.smooth_l1_loss(Qt, Gt)\n",
    "    \n",
    "    def train_step(self, sarsd):\n",
    "        state, action, reward, next_state, done = self.prep_sarsd(sarsd)\n",
    "        self.opt.zero_grad()\n",
    "        with torch.no_grad():\n",
    "            if self.double_dqn:\n",
    "                behaviour_actions = self.model_b(next_state).max(-1)[1]\n",
    "                one_hot = F.one_hot(behaviour_actions, self.action_atoms).to(self.device)\n",
    "                greedy_qvals_next = (self.model_t(next_state)*one_hot).sum(-1)\n",
    "            else:\n",
    "                greedy_qvals_next = self.model_t(next_state).max(-1)[0]\n",
    "            Gt = reward + (~done*self.discount * greedy_qvals_next)\n",
    "        action_mask = F.one_hot(action, self.action_atoms).to(self.device)\n",
    "        qvals = self.model_b(state)\n",
    "        Qt = (qvals*action_mask).sum(-1)\n",
    "        \n",
    "        loss = self.loss_fn(Qt, Gt)\n",
    "        loss.backward()\n",
    "        self.opt.step()\n",
    "        \n",
    "        td_error = (Gt-Qt).abs().mean().detach().item()\n",
    "        \n",
    "        self.update_target()\n",
    "        \n",
    "        return {'loss': loss.detach().item(), 'td_error': td_error, 'Qt': Qt.detach(), 'Gt': Gt.detach()}\n",
    "    \n",
    "    def update_target(self):\n",
    "        \"\"\"\n",
    "        Soft Update \n",
    "        \"\"\"\n",
    "        for behaviour, target in zip(self.model_b.parameters(), self.model_t.parameters()):\n",
    "            target.data.copy_(self.tau_soft_update * behaviour.data + \\\n",
    "                              (1.-self.tau_soft_update)*target.data)\n",
    "#         self.model_t.load_state_dict(self.model_b.state_dict())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class AgentMLP(AgentLM):\n",
    "    def __init__(self, config, feature_input_size, env, device=None):\n",
    "        super().__init__(config, feature_input_size, env, device)\n",
    "        d_model = config.agent_config.model_config.d_model\n",
    "        input_size = feature_input_size + len(config.assets)\n",
    "        self.model_b = nn.Sequential(nn.Linear(input_size, d_model), nn.ReLU(), \n",
    "                                     nn.Linear(d_model, self.action_atoms)).to(device).float()\n",
    "        self.model_t = nn.Sequential(nn.Linear(input_size, d_model), nn.ReLU(), \n",
    "                                     nn.Linear(d_model, self.action_atoms)).to(device).float()        \n",
    "        self.opt = torch.optim.Adam(self.model_b.parameters(), lr=config.agent_config.optim_config.lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [
     2,
     46
    ]
   },
   "outputs": [],
   "source": [
    "from madigan.fleet.conv_model import calc_conv_out_shape\n",
    "\n",
    "class DuelingHead(nn.Module):\n",
    "    \"\"\"\n",
    "    Replace normal output layer in DQN with this for Dueling Network Architectures\n",
    "    See: https://arxiv.org/pdf/1511.06581.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.value_net = nn.Linear(d_in, 1)\n",
    "        self.adv_net = nn.Linear(d_in, d_out)\n",
    "    def forward(self, x):\n",
    "        value = self.value_net(x)\n",
    "        adv = self.adv_net(x)\n",
    "        qvals = value + adv - adv.mean(-1, keepdim=True)\n",
    "        return qvals\n",
    "    \n",
    "class ConvModel(nn.Module):\n",
    "    def __init__(self, config, feature_input_size):\n",
    "        super().__init__()\n",
    "        nassets = len(config.assets)\n",
    "        d_model = config.agent_config.model_config.d_model\n",
    "        nactions = config.discrete_action_atoms\n",
    "        self.conv1 = nn.Conv1d(1, 32, 5)\n",
    "        self.conv2 = nn.Conv1d(32, 32, 5)\n",
    "        out_shape = calc_conv_out_shape(feature_input_size, [self.conv1, self.conv2])\n",
    "        self.fc1 = nn.Linear(nassets+out_shape[0]*32, d_model)\n",
    "        if config.agent_config.model_config.dueling:\n",
    "            self.output_head = DuelingHead(d_model, nactions)\n",
    "        else:\n",
    "            self.output_head = nn.Linear(d_model, nactions)\n",
    "        self.act = nn.GELU()     \n",
    "        \n",
    "    def forward(self, state):\n",
    "        price = state.price.transpose(-1, -2)\n",
    "        portfolio = state.portfolio\n",
    "        price_emb = self.act(self.conv1(price))\n",
    "        price_emb = self.act(self.conv2(price_emb)).view(price.shape[0], -1)\n",
    "\n",
    "        full_emb = torch.cat([price_emb, portfolio], dim=-1)\n",
    "        out = self.act(self.fc1(full_emb))\n",
    "\n",
    "        out = self.output_head(out)\n",
    "        return out\n",
    "        \n",
    "class AgentCNN(AgentLM):\n",
    "    def __init__(self, config, feature_input_size, env, device=None):\n",
    "        super().__init__(config, feature_input_size, env, device)\n",
    "        self.model_b = ConvModel(config, feature_input_size).to(device).float()\n",
    "        self.model_t = ConvModel(config, feature_input_size).to(device).float()\n",
    "\n",
    "        self.opt = torch.optim.Adam(self.model_b.parameters(), lr=config.agent_config.optim_config.lr)\n",
    "        \n",
    "    def prep_state(self, state, batch=False):\n",
    "        if not batch:\n",
    "            price = torch.as_tensor(state.price[None, ...], dtype=torch.float32).to(self.device)\n",
    "            port = torch.as_tensor(state.portfolio[None, -1], dtype=torch.float32).to(self.device)\n",
    "        else:\n",
    "            price = torch.as_tensor(state.price, dtype=torch.float32).to(self.device)\n",
    "            port = torch.as_tensor(state.portfolio[:, -1], dtype=torch.float32).to(self.device)\n",
    "#         timestamp = torch.as_tensor(state.timestamp)\n",
    "        return State(price, port, state.timestamp)\n",
    "\n",
    "    def prep_sarsd(self, sarsd):\n",
    "        state = self.prep_state(sarsd.state, batch=True)\n",
    "#         action = np.rint(sarsd.action // self.lot_unit_value) + self.action_atoms//2\n",
    "        action = ternarize_array(sarsd.action) + self.action_atoms // 2\n",
    "        action = torch.as_tensor(action, dtype=torch.long, device=self.device)[..., 0]\n",
    "        reward = torch.as_tensor(sarsd.reward, dtype=torch.float32, device=self.device)\n",
    "        next_state = self.prep_state(sarsd.next_state, batch=True)\n",
    "        done = torch.as_tensor(sarsd.done, dtype=torch.bool, device=self.device)\n",
    "        return state, action, reward, next_state, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class DuelingHeadIQN(nn.Module):\n",
    "    \"\"\"\n",
    "    Replace normal output layer in DQN with this for Dueling Network Architectures\n",
    "    See: https://arxiv.org/pdf/1511.06581.pdf\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.value_net = nn.Linear(d_in, 1)\n",
    "        self.adv_net = nn.Linear(d_in, d_out)\n",
    "    def forward(self, x):\n",
    "        value = self.value_net(x)\n",
    "        adv = self.adv_net(x)\n",
    "        qvals = value + adv - adv.mean(-1, keepdim=True)\n",
    "        return qvals\n",
    "    \n",
    "class TauEmbedLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    For use in distributional DQN approach I.e IQN, FQF\n",
    "    \"\"\"\n",
    "    def __init__(self, d_embed, d_model):\n",
    "        super().__init__()\n",
    "        self.d_embed = d_embed\n",
    "        self.projection = nn.Linear(d_embed, d_model)\n",
    "        self.act = nn.GELU()\n",
    "        self.spectrum_range = math.pi* torch.arange(1, self.d_embed+1, \n",
    "                                           dtype=torch.float).view(1, 1, self.d_embed)\n",
    "        \n",
    "    def forward(self, tau):\n",
    "        # embed using cos - like transformers\n",
    "        before = torch.cuda.memory_allocated()\n",
    "        spectrum = tau[:, :, None] * self.spectrum_range.to(tau.device)\n",
    "        basis = torch.cos(spectrum)\n",
    "        embedded = self.act(self.projection(basis))\n",
    "        after = torch.cuda.memory_allocated()\n",
    "#         print('Used by Tau Embed', after - before)\n",
    "#         del spectrum\n",
    "#         del basis\n",
    "#         del embedded\n",
    "        after = torch.cuda.memory_allocated()\n",
    "#         print('Used by Tau Embed after clean up', after - before)\n",
    "        return embedded\n",
    "    \n",
    "    \n",
    "class ConvModelIQN(nn.Module):\n",
    "    def __init__(self, config, feature_input_size):\n",
    "        super().__init__()\n",
    "        nassets = len(config.assets)\n",
    "        d_model = config.agent_config.model_config.d_model\n",
    "        tau_embed_size = config.agent_config.tau_embed_size\n",
    "        nactions = config.discrete_action_atoms\n",
    "        self.nTau = config.agent_config.nTau1\n",
    "        self.conv1 = nn.Conv1d(1, 32, 5)\n",
    "        self.conv2 = nn.Conv1d(32, 32, 5)\n",
    "        self.tau_embed_layer = TauEmbedLayer(tau_embed_size, d_model)\n",
    "        out_shape = calc_conv_out_shape(feature_input_size, [self.conv1, self.conv2])\n",
    "        self.fc1 = nn.Linear(nassets+out_shape[0]*32, d_model)\n",
    "        if config.agent_config.model_config.dueling:\n",
    "            self.output_head = DuelingHeadIQN(d_model, nactions)\n",
    "        else:\n",
    "            self.output_head = nn.Linear(d_model, nactions)\n",
    "        self.act = nn.GELU()     \n",
    "        \n",
    "    def forward(self, state, tau=None):\n",
    "        \n",
    "        price = state.price.transpose(-1, -2)\n",
    "        portfolio = state.portfolio\n",
    "        price_emb = self.act(self.conv1(price))\n",
    "        price_emb = self.act(self.conv2(price_emb)).view(price.shape[0], -1)\n",
    "\n",
    "        state_emb = torch.cat([price_emb, portfolio], dim=-1)\n",
    "        state_emb = self.act(self.fc1(state_emb))\n",
    "        if tau is None:\n",
    "            tau = torch.rand(state.price.shape[0], self.nTau,\n",
    "                            dtype=torch.float, device=state.price.device)\n",
    "#         before = torch.cuda.memory_allocated()\n",
    "        tau_emb = self.tau_embed_layer(tau)\n",
    "#         after = torch.cuda.memory_allocated()\n",
    "#         print('tau emb outside used: ', after-before)\n",
    "        full_emb = state_emb.unsqueeze(1) * tau_emb # (bs, nTau, d_model)\n",
    "        quantiles = self.output_head(full_emb) # (bs, nTau, n_actions)\n",
    "        return quantiles\n",
    "\n",
    "class AgentCNN_IQN(AgentLM):\n",
    "    def __init__(self, config, feature_input_size, env, device=None):\n",
    "        super().__init__(config, feature_input_size, env, device)\n",
    "        self.model_b = ConvModelIQN(config, feature_input_size).to(device).float()\n",
    "        self.model_t = ConvModelIQN(config, feature_input_size).to(device).float()\n",
    "        self.opt = torch.optim.Adam(self.model_b.parameters(), lr=config.agent_config.optim_config.lr)\n",
    "        self.nTau1 = config.agent_config.nTau1\n",
    "        self.nTau2 = config.agent_config.nTau2\n",
    "        self.k_huber = config.agent_config.k_huber\n",
    "        self.risk_distortion = lambda x: x\n",
    "        \n",
    "    def prep_state(self, state, batch=False):\n",
    "        if not batch:\n",
    "            price = torch.as_tensor(state.price[None, ...], dtype=torch.float32).to(self.device)\n",
    "            port = torch.as_tensor(state.portfolio[None, -1], dtype=torch.float32).to(self.device)\n",
    "        else:\n",
    "            price = torch.as_tensor(state.price, dtype=torch.float32).to(self.device)\n",
    "            port = torch.as_tensor(state.portfolio[:, -1], dtype=torch.float32).to(self.device)\n",
    "#         timestamp = torch.as_tensor(state.timestamp)\n",
    "\n",
    "        return State(price, port, state.timestamp)\n",
    "\n",
    "    def prep_sarsd(self, sarsd):\n",
    "        state = self.prep_state(sarsd.state, batch=True)\n",
    "#         action = np.rint(sarsd.action // self.lot_unit_value) + self.action_atoms//2\n",
    "        action = ternarize_array(sarsd.action) + self.action_atoms // 2\n",
    "        action = torch.as_tensor(action, dtype=torch.long, device=self.device)[..., 0]\n",
    "        reward = torch.as_tensor(sarsd.reward, dtype=torch.float32, device=self.device)\n",
    "        next_state = self.prep_state(sarsd.next_state, batch=True)\n",
    "        done = torch.as_tensor(sarsd.done, dtype=torch.bool, device=self.device)\n",
    "        return state, action, reward, next_state, done\n",
    "    \n",
    "    def get_quantiles(self, x, target=False):\n",
    "        x = self.prep_state(x)\n",
    "        if target:\n",
    "            quantiles = self.model_t(x)\n",
    "        else:\n",
    "            quantiles = self.model_b(x)\n",
    "        return quantiles.detach()\n",
    "    \n",
    "    def get_qvals(self, x, target=False):\n",
    "        quantiles = self.get_quantiles(x, target=target)   \n",
    "        qvals = quantiles.mean(1)\n",
    "        return qvals.detach()\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def __call__(self, x, target=False):\n",
    "        qvals = self.get_qvals(x, target=target)\n",
    "        actions = qvals.max(-1)[1]\n",
    "        return self.action_to_transaction(actions)\n",
    "    \n",
    "    def get_Gt(self, reward, done, next_state):\n",
    "        with torch.no_grad():\n",
    "            before = torch.cuda.memory_allocated()\n",
    "            tau_greedy = torch.rand(next_state.price.shape[0], self.nTau1, \n",
    "                                    dtype=torch.float, device=next_state.price.device,\n",
    "                                   requires_grad=False)\n",
    "            tau_greedy = self.risk_distortion(tau_greedy)\n",
    "            tau2 = torch.rand(next_state.price.shape[0], self.nTau2, \n",
    "                                dtype=torch.float, device=next_state.price.device,\n",
    "                                 requires_grad=False)\n",
    "            if self.double_dqn:\n",
    "                greedy_quantiles = self.model_b(next_state, tau=tau_greedy) #(bs, nTau1, nactions)\n",
    "            else:\n",
    "                greedy_quantiles = self.model_t(next_state, tau=tau_greedy) #(bs, nTau1, nactions)\n",
    "            greedy_actions = torch.argmax(greedy_quantiles.mean(1), dim=-1, keepdim=True) #(bs, 1)\n",
    "            assert greedy_actions.shape == (next_state.price.shape[0], 1)\n",
    "            one_hot_greedy = F.one_hot(greedy_actions, self.action_atoms).to(next_state.price.device)\n",
    "            quantiles_next_full = self.model_t(next_state, tau=tau2) #(bs, nTau1, nactions)\n",
    "            quantiles_next = (quantiles_next_full * one_hot_greedy).sum(-1) #(bs, nTau1)\n",
    "            # Add dim to reward and done to broadcast opeartions with quantiles_next \n",
    "            Gt = reward[:, None] + (~done[:, None] * self.discount * quantiles_next)\n",
    "            after = torch.cuda.memory_allocated()\n",
    "            print('Gt calc mem used: ', after-before)\n",
    "            del tau_greedy\n",
    "            del tau2\n",
    "            return Gt\n",
    "        \n",
    "    def train_step(self, sarsd):\n",
    "#         before_train = torch.cuda.memory_allocated()\n",
    "        print('before train mem_pct: ', mem_pct())\n",
    "        state, action, reward, next_state, done = self.prep_sarsd(sarsd)\n",
    "        self.opt.zero_grad()\n",
    "        print('tensors made mem_pct: ', mem_pct())\n",
    "        \n",
    "        tau1 = torch.rand(state.price.shape[0], self.nTau1, dtype=torch.float, \n",
    "                          device=state.price.device)\n",
    "        quantiles = self.model_b(state, tau=tau1)\n",
    "        \n",
    "        action_mask = F.one_hot(action[:, None], self.action_atoms).to(self.device)\n",
    "        \n",
    "        Gt = self.get_Gt(reward, done, next_state)\n",
    "        Qt = (quantiles*action_mask).sum(-1) #(bs, nTau1)\n",
    "        print('before loss mem_pct: ', mem_pct())\n",
    "        loss, td_error = self.loss_fn(Qt, Gt, tau1)\n",
    "#         before_loss = torch.cuda.memory_allocated()\n",
    "#         print('before loss backward mem used: ', before_loss - before_train)\n",
    "        print('after loss mem_pct: ', mem_pct())\n",
    "        loss.backward()\n",
    "        print('after loss backward mem_pct: ', mem_pct())\n",
    "#         after_loss = torch.cuda.memory_allocated()\n",
    "        \n",
    "#         print('after loss backward mem used: ', after_loss - before_train)\n",
    "        \n",
    "#         nn.utils.clip_grad_norm_(self.model_b.parameters(), 0.5)\n",
    "        self.opt.step()\n",
    "        \n",
    "        self.update_target()\n",
    "        \n",
    "#         after_train = torch.cuda.memory_allocated()\n",
    "#         print('after train inside function memory used = ', after_train-before_train)\n",
    "        \n",
    "        del state\n",
    "        del action\n",
    "        del reward\n",
    "        del next_state\n",
    "        del done\n",
    "        del tau1\n",
    "        del quantiles\n",
    "        del action_mask\n",
    "        print('after del mem_pct: ', mem_pct())\n",
    "#         after_train = torch.cuda.memory_allocated()\n",
    "#         print('after train inside function del memory used = ', after_train-before_train)\n",
    "        return {'loss': loss.detach().item(), \n",
    "                'td_error': td_error.detach().item(), \n",
    "#                 'Qt': Qt.detach(), 'Gt': Gt.detach()}\n",
    "                'Qt': Qt.detach().mean().item(), 'Gt': Gt.detach().mean().item()}\n",
    "    \n",
    "    def loss_fn(self, Qt, Gt, tau):\n",
    "        \"\"\"\n",
    "        Quantile Huber Loss\n",
    "        td_error: (bs, nTau1, nTau2)\n",
    "        \"\"\"\n",
    "        td_error = Gt.unsqueeze(1) - Qt.unsqueeze(-1)\n",
    "        \n",
    "        huber_loss = torch.where(td_error.abs() <= self.k_huber,\n",
    "                                 0.5*td_error.pow(2),\n",
    "                                 self.k_huber * (td_error.abs() - self.k_huber/2))\n",
    "        \n",
    "        assert huber_loss.shape == td_error.shape\n",
    "        \n",
    "        quantile_loss = torch.abs(tau[..., None] - (td_error.detach() < 0.).float()) * \\\n",
    "                        huber_loss  / self.k_huber\n",
    "        assert quantile_loss.shape == huber_loss.shape\n",
    "        \n",
    "        return quantile_loss.mean(-1).sum(-1).mean(), td_error.abs().mean()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class PerfectAgent:\n",
    "    def __init__(self, config):\n",
    "        self.config=config\n",
    "        self.action_atoms = config.discrete_action_atoms\n",
    "        self.params = self.config.generator_params\n",
    "        \n",
    "    def get_qvals(self, state):\n",
    "        prices = state.price\n",
    "        if self.config.data_source_type in  (\"Synth\", \"Triangle\"):\n",
    "            if prices[-3] < prices[-2] > prices[-1]:\n",
    "                return torch.tensor([[-1., 1.]])\n",
    "            elif prices[-3] > prices[-2] < prices[-1]:\n",
    "                return torch.tensor([[1., -1.]])\n",
    "            else:\n",
    "                return torch.randn((1, 2))\n",
    "        elif self.config.data_source_type == \"SawTooth\":\n",
    "            _max = np.array(self.params['amp']) + np.array(self.params['mu'])\n",
    "            if (_max - prices[-1] ) > (_max/1.25):\n",
    "                return torch.tensor([[1., -1.]])\n",
    "            return torch.tensor([[-1., 1.]])\n",
    "\n",
    "    def __call__(self, state):\n",
    "        qvals = self.get_qvals(state)\n",
    "        if qvals[0, 1] > qvals[0, 0]:\n",
    "            return np.array([1])\n",
    "        return np.array([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0133, -0.0374, -0.0245]], device='cuda:0') [9926.16314806]\n"
     ]
    }
   ],
   "source": [
    "agent = AgentLM(config, preprocessor.feature_output_size, env, device=device)\n",
    "agent = AgentMLP(config, preprocessor.feature_output_size, env, device=device)\n",
    "agent = AgentCNN(config, preprocessor.feature_output_size, env, device=device)\n",
    "agent = AgentCNN_IQN(config, preprocessor.feature_output_size, env, device=device)\n",
    "x = preprocessor.current_data()\n",
    "# x = agent.prep_state(x)\n",
    "qvals = agent.get_qvals(x)\n",
    "\n",
    "action = agent(x)\n",
    "print(qvals, action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "code_folding": [
     19
    ]
   },
   "outputs": [],
   "source": [
    "def trainer(agent, env, preprocessor, config):\n",
    "    rb = ReplayBuffer(config.rb_size, config.nstep_return)\n",
    "#     nstep_buffer = []\n",
    "    nstep=config.nstep_return\n",
    "    min_rb_size = config.min_rb_size\n",
    "    \n",
    "    eps = 1.\n",
    "    eps_decay = config.expl_eps_decay\n",
    "    eps_min = config.expl_eps_min\n",
    "    env.reset()\n",
    "    preprocessor.initialize_history(env)\n",
    "    state = preprocessor.current_data()\n",
    "    i = 0\n",
    "    running_reward = 0.\n",
    "    running_cost = 0.\n",
    "    while True:\n",
    "        trn_metrics=None\n",
    "        \n",
    "        if random.random() < eps:\n",
    "            units = 0.1 * env.availableMargin / env.currentPrices\n",
    "            actions = np.random.choice([-1., 0., 1.], len(units))\n",
    "            actions *= units\n",
    "            # actions = agent.action_space.sample)()\n",
    "        else:\n",
    "            actions = agent(state, target=False)\n",
    "        eps = max(eps_min, eps*eps_decay)\n",
    "        \n",
    "#         Prevent double positon\n",
    "#         for i, action in enumerate(actions):\n",
    "#             if np.sign(action) == np.sign(env.ledger):\n",
    "#                 actions[i] = 0.\n",
    "                \n",
    "        _next_state, reward, done, info = env.step(actions)\n",
    "        for cost in info.brokerResponse.transactionCost:\n",
    "            running_cost += cost\n",
    "#         reward = max(-1., min(reward, 1.))\n",
    "        preprocessor.stream_state(_next_state)\n",
    "        next_state = preprocessor.current_data()\n",
    "        if done:\n",
    "            reward = -1.\n",
    "        running_reward += reward\n",
    "        sarsd = SARSD(state, actions, reward, next_state, done)\n",
    "        rb.add(sarsd)\n",
    "#         nstep_buffer.append(sarsd)\n",
    "#         if len(nstep_buffer) == nstep:\n",
    "#             _reward = sum([dat.reward for dat in nstep_buffer])\n",
    "# #             _next_state = nstep_buffer[-1].next_state\n",
    "#             nstep_sarsd = nstep_buffer.pop(0)\n",
    "#             nstep_sarsd.reward = _reward\n",
    "#             rb.add(nstep_sarsd)\n",
    "        \n",
    "        if done:\n",
    "            env.reset()\n",
    "            preprocessor.initialize_history(env)\n",
    "            state = preprocessor.current_data()\n",
    "            print('running_reward: ', running_reward, 'running_cost: ', running_cost)\n",
    "\n",
    "            running_reward = 0.\n",
    "            running_cost = 0.\n",
    "        else:\n",
    "            state = next_state\n",
    "        if len(rb) >= min_rb_size:\n",
    "            sarsd = rb.sample(config.batch_size)\n",
    "            before = torch.cuda.memory_allocated()\n",
    "            trn_metrics = agent.train_step(sarsd)\n",
    "            after = torch.cuda.memory_allocated()\n",
    "            print('training mem used: ', after-before)\n",
    "            print('mem pct : ', mem_pct())\n",
    "            trn_metrics['eps'] = eps\n",
    "            trn_metrics['running_reward'] = running_reward\n",
    "            \n",
    "            \n",
    "#         if i % target_update_freq == 0:\n",
    "#             agent.model_t.load_state_dict(agent.model_b.state_dict())\n",
    "            \n",
    "        yield trn_metrics\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "def print_tensors():\n",
    "    for obj in gc.get_objects():\n",
    "        try:\n",
    "            if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
    "                print(type(obj), obj.size())\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "def print_tau_tensors():\n",
    "    for obj in gc.get_objects():\n",
    "        try:\n",
    "            if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
    "                if obj.shape in ((34, 32) , (34, 8)):\n",
    "                    print(type(obj), obj.size())\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "def print_scalar_tensors():\n",
    "    num = 0\n",
    "    for obj in gc.get_objects():\n",
    "        try:\n",
    "            if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
    "                if obj.shape == ():\n",
    "                    print(type(obj), obj.size())\n",
    "                    num += 1\n",
    "        except:\n",
    "            pass\n",
    "    print('num', num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 32])\n",
      "<class 'torch.Tensor'> torch.Size([34, 8])\n"
     ]
    }
   ],
   "source": [
    "print_tau_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.) tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "mem_pct = lambda : torch.cuda.memory_allocated() / torch.cuda.max_memory_allocated()\n",
    "mem_pct()\n",
    "\n",
    "a = torch.tensor(1., requires_grad=True)\n",
    "f = torch.tensor(2., requires_grad=True)\n",
    "\n",
    "c = a + f\n",
    "c.backward()\n",
    "print(a.grad, b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "<class 'torch.Tensor'> torch.Size([])\n",
      "num 11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c.backward()\n",
    "print_scalar_tensors()\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'basepath': '/media/hemu/Data/Markets/farm',\n",
       " 'experiment_id': 'SineQ',\n",
       " 'parent_id': '',\n",
       " 'overwrite_exp': False,\n",
       " 'transaction_cost_abs': 0.0,\n",
       " 'transaction_cost_rel': 0.01,\n",
       " 'slippage_abs': 0.0,\n",
       " 'slippage_rel': 0.0,\n",
       " 'env_type': 'Synth',\n",
       " 'data_source_type': 'OU',\n",
       " 'init_cash': 1000000,\n",
       " 'required_margin': 1.0,\n",
       " 'maintenance_margin': 0.25,\n",
       " 'generator_params': {'mean': [10.0],\n",
       "  'theta': [0.15],\n",
       "  'phi': [4.0],\n",
       "  'noise_var': [0.1]},\n",
       " 'assets': ['sine1'],\n",
       " 'lot_unit_value': 10000,\n",
       " 'n_assets': 1,\n",
       " 'discrete_actions': True,\n",
       " 'discrete_action_atoms': 3,\n",
       " 'preprocessor_type': 'WindowedStacker',\n",
       " 'preprocessor_config': {'window_length': 64},\n",
       " 'agent_type': 'DQN',\n",
       " 'agent_config': {'type': 'DQN',\n",
       "  'basepath': '/media/hemu/Data/Markets/farm',\n",
       "  'discrete_action_atoms': 3,\n",
       "  'model_config': {'model_class': 'ConvModel',\n",
       "   'd_model': 1024,\n",
       "   'n_layers': 4,\n",
       "   'n_feats': 1,\n",
       "   'action_atoms': 3,\n",
       "   'n_assets': 1,\n",
       "   'min_tf': 64,\n",
       "   'dueling': True,\n",
       "   'iqn': True,\n",
       "   'nTau1': 32,\n",
       "   'nTau2': 8,\n",
       "   'tau_embed_size': 64,\n",
       "   'discrete_actions': True,\n",
       "   'discrete_action_atoms': 3,\n",
       "   'lot_unit_value': 10000},\n",
       "  'optim_config': {'type': 'Adam',\n",
       "   'lr': 0.001,\n",
       "   'lr_critic': 0.001,\n",
       "   'lr_actor': 0.0001,\n",
       "   'eps': 1e-08,\n",
       "   'momentum': 0.9,\n",
       "   'betas': (0.9, 0.999),\n",
       "   'weight_decay': 0},\n",
       "  'double_dqn': True,\n",
       "  'dueling': True,\n",
       "  'iqn': True,\n",
       "  'nTau1': 32,\n",
       "  'nTau2': 8,\n",
       "  'k_huber': 1,\n",
       "  'tau_embed_size': 64,\n",
       "  'discount': 0.999,\n",
       "  'nstep_return': 5,\n",
       "  'action_atoms': 3,\n",
       "  'tau_soft_update': 0.0001,\n",
       "  'greedy_eps_testing': 0.0},\n",
       " 'model_config': {'model_class': 'ConvModel',\n",
       "  'd_model': 1024,\n",
       "  'n_layers': 4,\n",
       "  'n_feats': 1,\n",
       "  'action_atoms': 3,\n",
       "  'n_assets': 1,\n",
       "  'min_tf': 64,\n",
       "  'dueling': True,\n",
       "  'iqn': True,\n",
       "  'nTau1': 32,\n",
       "  'nTau2': 8,\n",
       "  'tau_embed_size': 64,\n",
       "  'discrete_actions': True,\n",
       "  'discrete_action_atoms': 3,\n",
       "  'lot_unit_value': 10000},\n",
       " 'optim_config': {'type': 'Adam',\n",
       "  'lr': 0.001,\n",
       "  'lr_critic': 0.001,\n",
       "  'lr_actor': 0.0001,\n",
       "  'eps': 1e-08,\n",
       "  'momentum': 0.9,\n",
       "  'betas': (0.9, 0.999),\n",
       "  'weight_decay': 0},\n",
       " 'nsteps': 1000000,\n",
       " 'test_steps': 1000,\n",
       " 'rb_size': 100000,\n",
       " 'episode_length': 1024,\n",
       " 'min_rb_size': 50000,\n",
       " 'train_freq': 4,\n",
       " 'target_update_freq': 32000,\n",
       " 'test_freq': 32000,\n",
       " 'log_freq': 10000,\n",
       " 'model_save_freq': 64000,\n",
       " 'min_tf': 64,\n",
       " 'batch_size': 34,\n",
       " 'nstep_return': 5,\n",
       " 'expl_eps': 1.0,\n",
       " 'expl_eps_min': 0.1,\n",
       " 'expl_eps_decay': 0.999999,\n",
       " 'reward_clip': (-1.0, 1.0)}"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = make_config(\n",
    "        experiment_id=\"SineQ\",\n",
    "        basepath=\"/media/hemu/Data/Markets/farm\",\n",
    "        overwrite_exp=False,\n",
    "        transaction_cost_rel=0.01,\n",
    "    \n",
    "    \n",
    "        test_steps=1_000,\n",
    "        nsteps=1_000_000,\n",
    "    \n",
    "        assets=[\"sine1\"],\n",
    "#         data_source_type=\"Triangle\",\n",
    "#         generator_params={\n",
    "#         'freq':[2.],\n",
    "#         'mu':[0.6],\n",
    "#         'amp':[.5],\n",
    "#         'phase':[0.],\n",
    "#         'dX':0.1,\n",
    "#         \"noise\": 0.0},\n",
    "#         data_source_type=\"SineAdder\",\n",
    "#         generator_params={\n",
    "#             'freq':[2.2, 4.1, 1., 3.],\n",
    "#             'mu':[.6, 0.3, 2., 4.2],\n",
    "#             'amp':[.5, 0.2, 0.4, 1.2],\n",
    "#             'phase':[0., 1., 4., 0.],\n",
    "#             'dX':0.01,\n",
    "#             \"noise\": 0.0},\n",
    "        data_source_type=\"OU\",\n",
    "        generator_params=dict(\n",
    "            mean=[10.],\n",
    "            theta=[.15],\n",
    "            phi = [4.],\n",
    "            noise_var = [.1]\n",
    "        ),\n",
    "        preprocessor_type=\"WindowedStacker\",\n",
    "        window_length=64,\n",
    "    \n",
    "        agent_type = \"DQN\",\n",
    "        discrete_actions=True,\n",
    "        discrete_action_atoms=3,\n",
    "        double_dqn=True,\n",
    "        dueling=True,\n",
    "        iqn=True,\n",
    "        nTau1=32,\n",
    "        nTau2=8,\n",
    "        k_huber=1,\n",
    "        nstep_return = 5,\n",
    "        tau_soft_update=1e-4,\n",
    "        rb_size=100_000,\n",
    "        min_rb_size=50_000,\n",
    "        batch_size=34,\n",
    "        discount = 0.999,\n",
    "        lot_unit_value=10_000,\n",
    "    \n",
    "        expl_eps_decay=0.999999,\n",
    "    \n",
    "        model_class=\"ConvModel\",\n",
    "        d_model = 1024,\n",
    "        lr=1e-3,\n",
    "\n",
    "    )\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make_env(config)\n",
    "\n",
    "# agent = make_agent(config)\n",
    "\n",
    "preprocessor = make_preprocessor(config)\n",
    "preprocessor.initialize_history(env)\n",
    "\n",
    "agent = AgentCNN(config, preprocessor.feature_output_size, env, device=device)\n",
    "agent = AgentCNN_IQN(config, preprocessor.feature_output_size, env, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# state_dict = torch.load('OU_IQN_behav.pth')['state_dict']\n",
    "# agent.model_b.load_state_dict(state_dict)\n",
    "# state_dict = torch.load('OU_IQN_target.pth')['state_dict']\n",
    "# agent.model_t.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing replay buffer with min # of experiences\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11d3bda1e7b8414e96d0f22c98012abf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running_reward:  -1.0649732749005743 running_cost:  227521.8578787314\n",
      "running_reward:  -0.8821535529832105 running_cost:  249059.97116919473\n",
      "running_reward:  -1.0892778953813227 running_cost:  56823.62256578188\n",
      "running_reward:  -2.2503707073559034 running_cost:  166817.40111989382\n",
      "running_reward:  -0.9498671107593346 running_cost:  70382.75403543968\n",
      "running_reward:  -1.0628276682476934 running_cost:  237350.79516336808\n",
      "running_reward:  -1.6939444567663184 running_cost:  406552.8692433329\n",
      "running_reward:  -1.1883397045771815 running_cost:  62014.43850378649\n",
      "running_reward:  -0.9972648379874804 running_cost:  54616.15956629417\n",
      "running_reward:  -1.1841331637475367 running_cost:  109973.6328120437\n",
      "running_reward:  -0.9329784267766865 running_cost:  36084.20148091377\n",
      "running_reward:  -1.0128728438572892 running_cost:  25640.50085098814\n",
      "running_reward:  -0.9873132126759412 running_cost:  22990.629723360114\n",
      "running_reward:  -1.7720013132990071 running_cost:  347354.9445487365\n",
      "running_reward:  -1.0750264186679104 running_cost:  56905.852053641705\n",
      "running_reward:  -0.9989249883317711 running_cost:  254111.6433141398\n",
      "running_reward:  -0.886439429435276 running_cost:  20942.53472787692\n",
      "running_reward:  -0.9295683899552042 running_cost:  19282.336236833435\n",
      "running_reward:  -0.9234506420134708 running_cost:  157417.17496430292\n",
      "running_reward:  -1.0178282227582152 running_cost:  155606.80405529687\n",
      "running_reward:  -2.433121040766559 running_cost:  402084.38771655934\n",
      "running_reward:  -1.7856373502927114 running_cost:  660078.1522505102\n",
      "running_reward:  -0.8815251055442518 running_cost:  22555.632735885614\n",
      "running_reward:  -0.9585980377605268 running_cost:  185655.57402062888\n",
      "running_reward:  -1.0188106152475371 running_cost:  63254.286579030646\n",
      "running_reward:  -0.9241799496419103 running_cost:  11033.06804006173\n",
      "running_reward:  -1.0202027602948422 running_cost:  171261.76801992193\n",
      "running_reward:  -0.9950736765958815 running_cost:  39755.66337653583\n",
      "running_reward:  -1.1251126292107207 running_cost:  88671.47103981972\n",
      "running_reward:  -1.0741854657096703 running_cost:  11680.833030796628\n",
      "running_reward:  -0.9958703934105574 running_cost:  25189.241354580077\n",
      "running_reward:  -1.0789320301756822 running_cost:  48674.06466656241\n",
      "running_reward:  -1.0084870818385507 running_cost:  21111.419385803427\n",
      "running_reward:  -1.054814252196812 running_cost:  47865.633658330014\n",
      "running_reward:  -1.1484331503306482 running_cost:  162612.26979129238\n",
      "running_reward:  -1.0991303634397738 running_cost:  356620.92475612136\n",
      "running_reward:  -1.0479540760957697 running_cost:  24786.728352539038\n",
      "running_reward:  -1.0008016872982255 running_cost:  48181.1469152667\n",
      "running_reward:  -1.0278726302596104 running_cost:  21781.933461235465\n",
      "running_reward:  -1.0285213115444247 running_cost:  94867.48066892245\n",
      "running_reward:  -1.132434876072208 running_cost:  376511.858743327\n",
      "running_reward:  -2.544783362502151 running_cost:  169644.70973570074\n",
      "running_reward:  -1.9348247914142624 running_cost:  164176.3488534904\n",
      "running_reward:  -0.9810269527674019 running_cost:  30560.535358855035\n",
      "running_reward:  -1.1045516148256764 running_cost:  90507.89455874452\n",
      "running_reward:  -1.2896833044076144 running_cost:  307466.8820975193\n",
      "running_reward:  -0.9735251196920208 running_cost:  54728.82374283834\n",
      "running_reward:  -1.0493862525478397 running_cost:  194148.34591162048\n",
      "running_reward:  -1.1023237611101375 running_cost:  657533.3088258083\n",
      "running_reward:  -0.9285127340530768 running_cost:  97511.87852199585\n",
      "running_reward:  -1.106542171351959 running_cost:  191304.97188223473\n",
      "running_reward:  -0.9746387931552406 running_cost:  22694.936860207905\n",
      "running_reward:  -1.0256276206854114 running_cost:  10491.956624482218\n",
      "running_reward:  -1.0102136829103558 running_cost:  17012.8206607095\n",
      "running_reward:  -1.0683251997882022 running_cost:  14181.524188280664\n",
      "running_reward:  -2.1910852692486733 running_cost:  403629.95526503335\n",
      "running_reward:  -1.025931577597403 running_cost:  18369.22138923126\n",
      "running_reward:  -1.610469958758788 running_cost:  457279.087799079\n",
      "running_reward:  -1.1591018393058339 running_cost:  225224.7024914305\n",
      "running_reward:  -1.032038612077197 running_cost:  85392.87059120997\n",
      "running_reward:  -0.8733504828615353 running_cost:  106294.80002765903\n",
      "running_reward:  -1.0010716841728213 running_cost:  41704.467957163804\n",
      "running_reward:  -2.431940931684317 running_cost:  290605.041976889\n",
      "running_reward:  -1.0611178641641805 running_cost:  9975.800238159678\n",
      "running_reward:  -1.0855824754828922 running_cost:  55956.50107389957\n",
      "running_reward:  -1.0680571996177572 running_cost:  277301.44079971436\n",
      "running_reward:  -1.008848583970344 running_cost:  21917.583571503346\n",
      "running_reward:  -0.8997559378943161 running_cost:  34376.980888992155\n",
      "running_reward:  -0.9044600869312991 running_cost:  150437.64867071508\n",
      "running_reward:  -1.060773004169287 running_cost:  14868.416381556817\n",
      "running_reward:  -1.0734631996476545 running_cost:  95316.33073610472\n",
      "running_reward:  -0.9745042227252672 running_cost:  454888.2483328561\n",
      "running_reward:  -1.0269320851737855 running_cost:  86095.67936305948\n",
      "running_reward:  -1.0524401086407171 running_cost:  124880.25658875711\n",
      "running_reward:  -1.105190379683799 running_cost:  46798.16974429829\n",
      "running_reward:  -1.1255941345205467 running_cost:  116667.39179976503\n",
      "running_reward:  -0.9735112343855087 running_cost:  35428.914065197096\n",
      "running_reward:  -1.020382493289952 running_cost:  45126.03306292487\n",
      "running_reward:  -1.0210117031790595 running_cost:  190458.37237464098\n",
      "running_reward:  -0.9017395630890089 running_cost:  12314.370733290623\n",
      "running_reward:  -1.0943665663065 running_cost:  155771.68383554192\n",
      "running_reward:  -0.9888391527899525 running_cost:  32995.55385474211\n",
      "running_reward:  -0.9951128700981565 running_cost:  42874.81149197814\n",
      "running_reward:  -0.93941799173472 running_cost:  24513.319614799126\n",
      "running_reward:  -1.0141542816679527 running_cost:  167842.5760818337\n",
      "running_reward:  -1.0155029069001198 running_cost:  24662.45749185429\n",
      "running_reward:  -0.9721800623338596 running_cost:  187791.15888835042\n",
      "running_reward:  -1.0476543144267132 running_cost:  15711.97620020838\n",
      "running_reward:  -1.050753691892174 running_cost:  19468.069094505765\n",
      "running_reward:  -1.1632261561308415 running_cost:  264468.6346414009\n",
      "running_reward:  -0.9603289574917163 running_cost:  26886.78016880366\n",
      "running_reward:  -1.0516723403832144 running_cost:  12221.41758037733\n",
      "running_reward:  -0.8644340427503773 running_cost:  448443.7124680393\n",
      "running_reward:  -1.0188067335980586 running_cost:  37219.64168859973\n",
      "running_reward:  -1.0257867208251281 running_cost:  51504.34143680161\n",
      "running_reward:  -0.9723561578762482 running_cost:  118842.45151808696\n",
      "running_reward:  -1.05876955969695 running_cost:  71790.32806762621\n",
      "running_reward:  -0.9938829153658983 running_cost:  17234.05409398263\n",
      "running_reward:  -0.8008703097703214 running_cost:  139927.39811732768\n",
      "running_reward:  -1.0130476464427614 running_cost:  30778.10682035119\n",
      "running_reward:  -1.00726014688899 running_cost:  65361.31505164771\n",
      "running_reward:  -1.2587515719968985 running_cost:  567661.0813502033\n",
      "running_reward:  -1.0053947641036647 running_cost:  37789.94431947745\n",
      "running_reward:  -1.027255488347213 running_cost:  23286.554940668746\n",
      "running_reward:  -1.0387462961656022 running_cost:  32569.841115272156\n",
      "running_reward:  -1.0376562138699381 running_cost:  17433.368740055746\n",
      "running_reward:  -0.8596831067441622 running_cost:  329473.3984952337\n",
      "running_reward:  -1.1767681100778102 running_cost:  112468.03879091195\n",
      "running_reward:  -1.0163399447990709 running_cost:  38585.471158460794\n",
      "running_reward:  -1.1107007413398906 running_cost:  50258.53603067309\n",
      "running_reward:  -1.0749894472323045 running_cost:  51468.500182770826\n",
      "running_reward:  -0.9896117133345409 running_cost:  67428.10490813405\n",
      "running_reward:  -1.083886023137844 running_cost:  285684.0742859501\n",
      "running_reward:  -0.9867196135610775 running_cost:  24560.220129643887\n",
      "running_reward:  -1.042578005595135 running_cost:  197052.87204745456\n",
      "running_reward:  -1.049148527115497 running_cost:  29975.32616175821\n",
      "running_reward:  -0.9794956191308641 running_cost:  32440.563849396625\n",
      "running_reward:  -1.0127444207055325 running_cost:  36346.64660657795\n",
      "running_reward:  -0.966030444377366 running_cost:  46788.694787419394\n",
      "running_reward:  -1.0655935371847427 running_cost:  66112.10576732206\n",
      "running_reward:  -1.041363793096686 running_cost:  33843.881538282396\n",
      "running_reward:  -0.920547370775862 running_cost:  22211.919184543112\n",
      "running_reward:  -0.8944973804539847 running_cost:  27375.625515287393\n",
      "running_reward:  -0.9532284682539417 running_cost:  25047.15432649294\n",
      "running_reward:  -1.0001042156368722 running_cost:  50649.13075711611\n",
      "running_reward:  -0.964929121883487 running_cost:  57711.97000254729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running_reward:  -1.2941770178863479 running_cost:  331961.2419915667\n",
      "running_reward:  -2.004371415356714 running_cost:  370119.08198429307\n",
      "running_reward:  -1.0211103394431087 running_cost:  37851.72315683952\n",
      "running_reward:  -0.9014809392951832 running_cost:  312514.6915021585\n",
      "running_reward:  -0.8333177914310804 running_cost:  28798.96769150504\n",
      "running_reward:  -1.0546972151988836 running_cost:  131908.84076910446\n",
      "running_reward:  -1.012203288539522 running_cost:  94488.71796077164\n",
      "running_reward:  -1.0613422721447832 running_cost:  66820.4339413841\n",
      "running_reward:  -0.8531837285378171 running_cost:  135138.767178668\n",
      "running_reward:  -1.0328693507451632 running_cost:  34979.68160323335\n",
      "running_reward:  -1.1535079353421382 running_cost:  113293.02637332736\n",
      "running_reward:  -0.9494316567255884 running_cost:  47977.904824681245\n",
      "running_reward:  -1.1319215095112838 running_cost:  76713.49917504765\n",
      "running_reward:  -1.0207105354546948 running_cost:  60295.6281191697\n",
      "running_reward:  -0.9994048914209583 running_cost:  85151.71903401395\n",
      "running_reward:  -0.9555429999678148 running_cost:  25793.01734058632\n",
      "running_reward:  -1.0261879776738325 running_cost:  63730.72757956426\n",
      "running_reward:  -1.1008102156085215 running_cost:  129836.05557685316\n",
      "running_reward:  -1.0957273877243587 running_cost:  364179.8712264377\n",
      "running_reward:  -1.0522561950285922 running_cost:  25987.50442530903\n",
      "running_reward:  -0.9562857086539419 running_cost:  28654.567589692502\n",
      "running_reward:  -1.0714471258118254 running_cost:  565029.2246144613\n",
      "running_reward:  -0.9536631620819036 running_cost:  42826.56210819665\n",
      "running_reward:  -0.9713311762363391 running_cost:  72991.75872875348\n",
      "running_reward:  -1.305336699909918 running_cost:  185751.32467874614\n",
      "running_reward:  -1.0674915393980196 running_cost:  12170.970547387353\n",
      "running_reward:  -0.7279407344921898 running_cost:  247316.10291278097\n",
      "running_reward:  -0.9392197294985553 running_cost:  35567.766478021374\n",
      "running_reward:  -0.987999182753394 running_cost:  27609.84003280848\n",
      "running_reward:  -1.013362519830642 running_cost:  45369.25950010227\n",
      "running_reward:  -0.9150236529091216 running_cost:  60603.470163841324\n",
      "running_reward:  -0.8725463311974103 running_cost:  54449.86373727288\n",
      "running_reward:  -0.8808041268476011 running_cost:  183615.74501138882\n",
      "running_reward:  -1.118359872974254 running_cost:  225085.18585961353\n",
      "running_reward:  -1.088763536607031 running_cost:  63683.51655412022\n",
      "running_reward:  -0.9767975982195911 running_cost:  97316.599445984\n",
      "running_reward:  -0.972963385913124 running_cost:  48621.73300569778\n",
      "running_reward:  -1.1839331818947536 running_cost:  219547.83592975602\n",
      "running_reward:  -1.0687545178175077 running_cost:  110630.49844535066\n",
      "running_reward:  -0.8637466805254852 running_cost:  192464.53080048977\n",
      "running_reward:  -1.0590951276012377 running_cost:  67341.12363562554\n",
      "running_reward:  -1.0380010274374578 running_cost:  46027.25755741576\n",
      "running_reward:  -0.9986809736267304 running_cost:  53982.78521505415\n",
      "running_reward:  -0.9690963127619102 running_cost:  46819.32806883618\n",
      "running_reward:  -0.9237085191482814 running_cost:  216467.36422151033\n",
      "running_reward:  -1.0845207969281632 running_cost:  196312.32269642543\n",
      "running_reward:  -2.230303622491169 running_cost:  448486.64740544825\n",
      "running_reward:  -1.0583321814595401 running_cost:  10772.450364306527\n",
      "running_reward:  -0.9799514100185539 running_cost:  32271.47390447703\n",
      "running_reward:  -2.183337805763246 running_cost:  371887.80030153564\n",
      "running_reward:  -1.0417416236389447 running_cost:  16298.13073470265\n",
      "running_reward:  -0.9888002232928647 running_cost:  21016.059445709096\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loop = iter(trainer(agent, env, preprocessor, config))\n",
    "# INITIALIZE REPLAY BUFFER\n",
    "print(\"Initializing replay buffer with min # of experiences\")\n",
    "for i in tqdm(range(config.min_rb_size)):\n",
    "    metrics = next(train_loop)\n",
    "    \n",
    "train_metrics=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab6e430d6325417485d35c09a5a7cf2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before train mem_pct:  0.11040673114254423\n",
      "tensors made mem_pct:  0.11051972811190756\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.19518632910512196\n",
      "after loss mem_pct:  0.1956354196243865\n",
      "after loss backward mem_pct:  0.15418001865898673\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  22963200\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "running_reward:  -0.6875597094381574 running_cost:  267074.5474773088\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "running_reward:  -1.4745841121889527 running_cost:  487338.10633493506\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "running_reward:  -1.1362078604640413 running_cost:  54904.727879487575\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "before train mem_pct:  0.2403532459103789\n",
      "tensors made mem_pct:  0.24046624287974225\n",
      "Gt calc mem used:  27648\n",
      "before loss mem_pct:  0.32513284387295666\n",
      "after loss mem_pct:  0.32558193439222116\n",
      "after loss backward mem_pct:  0.24081102850420985\n",
      "after del mem_pct:  0.2405908292818608\n",
      "training mem used:  0\n",
      "mem pct :  0.2403532459103789\n",
      "\n",
      "eps 0.9493288421589038\n"
     ]
    }
   ],
   "source": [
    "iterations = 2_000\n",
    "# train_loop = iter(trainer(agent, env, preprocessor, config))\n",
    "env.reset()\n",
    "for i in tqdm(range(iterations)):\n",
    "    metrics = next(train_loop)\n",
    "    if metrics is not None:\n",
    "        train_metrics.append(metrics)\n",
    "        \n",
    "print('eps', metrics['eps'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7efbcfad0850>"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x540 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "figsize(10, 7.5)\n",
    "from madigan.utils.plotting import plot_train_metrics\n",
    "\n",
    "trn_metrics = reduce_train_metrics(list_2_dict(train_metrics), ['Qt', 'Gt'])\n",
    "# plt.plot(np.clip(trn_metrics['loss'], 0., 10.), label='loss')\n",
    "# plt.plot(np.clip(trn_metrics['td_error'], 0., 10.), label='td_error')\n",
    "plt.plot(trn_metrics['loss'], label='loss')\n",
    "plt.plot(trn_metrics['td_error'], label='td_error')\n",
    "plt.plot(trn_metrics['Qt'], label='Qt')\n",
    "plt.plot(trn_metrics['Gt'], label='Gt')\n",
    "plt.legend()\n",
    "# plot_train_metrics(trn_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['equity', 'returns', 'prices', 'positions', 'assets', 'cash', 'margin', 'actions', 'states', 'qvals'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from madigan.utils.plotting import plot_test_metrics\n",
    "figsize(15, 10)\n",
    "reset=True\n",
    "# reset=False\n",
    "\n",
    "tst_metrics = test(agent, env, preprocessor, \n",
    "                   nsteps=640, verbose=True, reset=reset, eps=0.)\n",
    "print(tst_metrics.keys())\n",
    "\n",
    "fig, ax = plot_test_metrics(tst_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {'state_dict': agent.model_b.state_dict(),\n",
    "         'ntraining_steps': i, \n",
    "        'config': config}\n",
    "torch.save(state, 'OU_IQN_behav.pth')\n",
    "state = {'state_dict': agent.model_t.state_dict(),\n",
    "         'ntraining_steps': i, \n",
    "        'config': config}\n",
    "torch.save(state, 'OU_IQN_target.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(agent.model_t.parameters())\n",
    "print(\"biases\", params[1])\n",
    "weights = params[0].detach().cpu().numpy()\n",
    "for i in range(0, 64):    \n",
    "    plt.plot(weights[i], label=str(i))\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "perfect_agent = PerfectAgent(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_metrics = test(perfect_agent, env, preprocessor, verbose=True)\n",
    "print(tst_metrics.keys())\n",
    "fig, ax = plot_test_metrics(tst_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perfect_agent.get_qvals(preprocessor.current_data()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.current_data().price.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
