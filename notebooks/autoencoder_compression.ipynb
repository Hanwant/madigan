{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from pathlib import Path \n",
    "import zipfile\n",
    "from functools import reduce\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.pylabtools import figsize\n",
    "\n",
    "\n",
    "from madigan.modelling.net.utils import calc_conv_out_shape, calc_pad_to_conserve\n",
    "\n",
    "figsize(8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = Path(\"/media/hemu/Data/Markets/FX/truefx/GBPJPY-zip\")\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_parse_truefx(filepath):\n",
    "    df = pd.read_csv(filepath, header=None, parse_dates=True)\n",
    "    df.columns = ('asset', 'timestamp', 'bid', 'ask')\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    return df.drop('asset', axis=1).set_index('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_aggregate_truefx(filepaths, timeframe='1h'):\n",
    "    dfs = []\n",
    "    for file in tqdm(filepaths):\n",
    "        df = read_and_parse_truefx(file)\n",
    "        df = df.resample(timeframe).last().dropna()\n",
    "        dfs.append(df)\n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96ebca072e554adb9131b519d75acb3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "291bc1d04cc147749e1056e6c40938dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "files = list(datapath.iterdir())\n",
    "files.sort()\n",
    "print(len(files))\n",
    "\n",
    "trn_df = load_and_aggregate_truefx(files[:50], '1min')\n",
    "tst_df = load_and_aggregate_truefx(files[50: 60], '1min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length:  1502256 \n",
      "                          bid      ask\n",
      "timestamp                            \n",
      "2009-05-01 00:00:00  146.372  146.408\n",
      "2009-05-01 00:01:00  146.380  146.425\n",
      "2009-05-01 00:02:00  146.393  146.468\n",
      "2009-05-01 00:03:00  146.410  146.472\n",
      "2009-05-01 00:04:00  146.397  146.446\n",
      "length:  302966 \n",
      "                          bid      ask\n",
      "timestamp                            \n",
      "2013-07-01 00:00:00  151.189  151.239\n",
      "2013-07-01 00:01:00  151.152  151.227\n",
      "2013-07-01 00:02:00  151.115  151.184\n",
      "2013-07-01 00:03:00  151.166  151.220\n",
      "2013-07-01 00:04:00  151.209  151.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hemu/miniconda3/envs/madigan/lib/python3.7/site-packages/IPython/core/pylabtools.py:132: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %matplotlib notebook\n",
    "%matplotlib inline\n",
    "print('length: ', len(trn_df), '\\n', trn_df.head())\n",
    "print('length: ', len(tst_df), '\\n', tst_df.head())\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(trn_df.mean(axis=1), label='train')\n",
    "ax.plot(tst_df.mean(axis=1), label='test')\n",
    "ax.legend()\n",
    "fig.autofmt_xdate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df.mean(axis=1)\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.df[idx].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedWindow(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, window_length):\n",
    "        self.data = df.mean(axis=1).to_numpy().astype(np.float32)\n",
    "#         self.data = df['C'].to_numpy().astype(np.float32)\n",
    "        self.k = window_length\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.k\n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, slice):\n",
    "            idx = slice(idx.start+self.k, idx.stop+self.k)\n",
    "        else:\n",
    "            idx = idx + self.k\n",
    "        data = (self.data[idx - self.k: idx])\n",
    "        return data, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AE_MLP(nn.Module):\n",
    "    \"\"\"\n",
    "        Symmetric - number of encoding layers == number of deconding layers\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, encoded_size, d_model, n_encoding_layers):\n",
    "        super().__init__()\n",
    "        self.inp_sz = input_size\n",
    "        self.enc_dz = encoded_size\n",
    "        self.act_fn = nn.Tanh()\n",
    "        bias = False\n",
    "        layers = [nn.Linear(input_size, d_model, bias=bias), self.act_fn]\n",
    "        for i in range(n_encoding_layers):\n",
    "            layers.append(nn.Linear(d_model, d_model))\n",
    "            layers.append(self.act_fn)\n",
    "        self.encoder = nn.Sequential(*layers, nn.Linear(d_model, encoded_size, bias=bias))\n",
    "        layers = [nn.Linear(encoded_size, d_model, bias=bias)]\n",
    "        for i in range(n_encoding_layers):\n",
    "            layers.append(nn.Linear(d_model, d_model, bias=bias))\n",
    "            layers.append(self.act_fn)\n",
    "        self.decoder = nn.Sequential(*layers, nn.Linear(d_model, input_size, bias=bias))        \n",
    "        \n",
    "    def forward(self, x):\n",
    "#         with torch.no_grad():\n",
    "#             norm = x[:, -1][..., None]\n",
    "#             x = x / norm\n",
    "        # NORMALIZE\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        x = (x - mean) / std\n",
    "        encoded = self.act_fn(self.encoder(x))\n",
    "        decoded = self.decoder(encoded)\n",
    "        # DENORMALIZE\n",
    "        decoded = (decoded * std) + mean\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import relu, gelu\n",
    "\n",
    "class AE_CNN_SYMM(nn.Module):\n",
    "    \"\"\"\n",
    "        Symmetric - number of encoding layers == number of deconding layers\n",
    "        all Conv1D layers have the same number of channels == d_model\n",
    "        d_fc is the size of fc projection after the encoded bottleneck, \n",
    "        before passing on to Conv1dTranspose layers\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, encoded_size, d_model, d_fc,\n",
    "                 n_encoding_layers, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.inp_sz = input_size\n",
    "        self.enc_dz = encoded_size\n",
    "        self.d_model = d_model\n",
    "        self.d_fc = d_fc\n",
    "        self.dropout = dropout\n",
    "        self.act = nn.GELU()\n",
    "        \n",
    "        bias = False\n",
    "        layers = [nn.Conv1d(1, d_model, 5, bias=bias), self.act]\n",
    "        for i in range(n_encoding_layers):\n",
    "            layers.append(nn.Conv1d(d_model,  d_model, 5, bias=bias))\n",
    "            layers.append(self.act)\n",
    "            layers.append(nn.BatchNorm1d(d_model))\n",
    "            \n",
    "        self.encoder_conv = nn.Sequential(*layers)\n",
    "        out_shape = calc_conv_out_shape(input_size, layers)[0]\n",
    "        self.encoder_fc = nn.Linear(out_shape*d_model, encoded_size, bias=bias)\n",
    "        self.decoder_fc = nn.Linear(encoded_size, d_fc*out_shape, bias=bias)\n",
    "        \n",
    "        layers = [nn.ConvTranspose1d(d_fc, d_model, 5, bias=bias),\n",
    "                 self.act]\n",
    "        for i in range(n_encoding_layers-1):\n",
    "            layers.append(nn.ConvTranspose1d(d_model, d_model, 5, bias=bias))\n",
    "            layers.append(self.act)\n",
    "            layers.append(nn.BatchNorm1d(d_model))\n",
    "        self.decoder_conv = nn.Sequential(*layers, nn.ConvTranspose1d(d_model, 1, 5, bias=bias))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        x = (x-mean) / std\n",
    "        x = x[..., None].transpose(1, -1)\n",
    "        x = self.encoder_conv(x).reshape(x.shape[0], -1)\n",
    "        x = self.act(self.encoder_fc(x))\n",
    "        x = self.act(self.decoder_fc(x))\n",
    "        x = x.reshape(x.shape[0], self.d_fc, -1)\n",
    "        x = self.decoder_conv(x)[:, 0, :]        \n",
    "        return mean + (x * std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE_CNN(nn.Module):\n",
    "    \"\"\"\n",
    "    AutoEncoder using 1D convolutions\n",
    "    After the bottleneck (of size encoded_size)\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, encoder_channels,\n",
    "                 encoded_size, d_fc, decoder_channels,\n",
    "                 strides, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.inp_sz = input_size\n",
    "        self.enc_dz = encoded_size\n",
    "        self.d_fc = d_fc\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.act = nn.GELU()\n",
    "        kernel_size = 5\n",
    "        bias = True\n",
    "        groups = 1\n",
    "        \n",
    "        encoder_channels = [1] + encoder_channels\n",
    "        layers=[]\n",
    "        for i in range(1, len(encoder_channels)):\n",
    "            conv = nn.Conv1d(encoder_channels[i-1], encoder_channels[i],\n",
    "                             kernel_size, \n",
    "                             strides=strides[i],\n",
    "                             bias=bias, \n",
    "                             groups=min(max(\n",
    "                                 encoder_channels[i-1]//groups, 1), groups),\n",
    "                             padding = (kernel_size-1)//2)\n",
    "#             padding = calc_pad_to_conserve(input_size, conv, causal_dim=0)\n",
    "#             print(padding)\n",
    "#             layers.append(nn.ReplicationPad1d(padding = padding[0]//2))\n",
    "#             layers.append(nn.ZeroPad1d(padding = padding[0]//2))\n",
    "            layers.append(conv)\n",
    "            layers.append(self.act)\n",
    "            layers.append(nn.BatchNorm1d(encoder_channels[i]))\n",
    "            \n",
    "        self.encoder_conv = nn.Sequential(*layers)\n",
    "        \n",
    "        out_sz = calc_conv_out_shape(input_size, layers)[0]\n",
    "        self.encoder_fc = nn.Linear(out_sz*encoder_channels[-1],\n",
    "                                    encoded_size, bias=bias)\n",
    "        \n",
    "        decoder_channels = [d_fc] + decoder_channels\n",
    "        layers=[]\n",
    "        for i in range(1, len(decoder_channels)):\n",
    "            layers.append(nn.ConvTranspose1d(decoder_channels[i-1],\n",
    "                                             decoder_channels[i], \n",
    "                                             5, groups=groups, bias=bias))\n",
    "            layers.append(self.act)\n",
    "            layers.append(nn.BatchNorm1d(decoder_channels[i]))\n",
    "            \n",
    "        self.decoder_conv = nn.Sequential(\n",
    "            *layers, nn.ConvTranspose1d(decoder_channels[-1], 1, 5, bias=bias))\n",
    "        \n",
    "        # decoder_fc is earlier in the call graph\n",
    "        # but decoder_conv output is used to adaptively determine dec_sz\n",
    "        # so is intialized after decoder_conv\n",
    "        dec_sz = out_sz // 2 # reasonable starting value\n",
    "        dummy_input = torch.randn(1, d_fc, dec_sz)\n",
    "        while self.decoder_conv(dummy_input).shape[-1] < input_size:\n",
    "            dec_sz += 1\n",
    "            dummy_input = torch.randn(1, d_fc, dec_sz)\n",
    "        self.decoder_fc = nn.Linear(encoded_size, d_fc*dec_sz, bias=bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "#         mean = torch.zeros_like(x)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "#         std = torch.ones_like(mean)\n",
    "        x = (x-mean) / std\n",
    "        x = x[..., None].transpose(1, -1)\n",
    "        x = self.encoder_conv(x).reshape(x.shape[0], -1)\n",
    "        x = self.act(self.encoder_fc(x))\n",
    "        x = self.act(self.decoder_fc(x))\n",
    "        x = self.dropout(x.reshape(x.shape[0], self.d_fc, -1))\n",
    "        x = self.decoder_conv(x)[:, 0, :]        \n",
    "        return mean + (x * std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_size(model):\n",
    "     return reduce(lambda x,y:x+y,\n",
    "                   [reduce(lambda x,y:x+y, p.shape)\n",
    "                    for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(model, dataloader, device, lr=1e-3):\n",
    "    loss_fn = nn.MSELoss()\n",
    "    loss_fn = nn.L1Loss()\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    print_freq = max(len(dataloader) // 100, 100)\n",
    "    model.train()\n",
    "    for i, (x, idx) in enumerate(iter(dataloader)):\n",
    "        opt.zero_grad()\n",
    "        x = x.to(device)\n",
    "        y = x\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        _loss = loss.detach().item()\n",
    "        yield _loss\n",
    "        if i % print_freq == 0:\n",
    "            print(_loss, end='\\r', flush=True)\n",
    "        \n",
    "@torch.no_grad()\n",
    "def test(model, dataloader, device):\n",
    "    loss_fn = nn.MSELoss()\n",
    "    loss_fn = nn.L1Loss()\n",
    "    losses = []\n",
    "    xs = []\n",
    "    preds = []\n",
    "    model.eval()\n",
    "    for i, (x, idx) in enumerate(iter(dataloader)):\n",
    "        x = x.to(device)\n",
    "        y = x\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(pred, y)\n",
    "        losses.append(loss.detach().item())\n",
    "        xs.append(x.cpu().numpy())\n",
    "        preds.append(pred.cpu().numpy())\n",
    "    return {'loss': losses, 'x': xs, 'pred': preds}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_performance(metrics, accumulate_returns=False):\n",
    "    fig, ax = plt.subplots(4, 4, figsize=(15, 15))\n",
    "    axs = ax.flatten()\n",
    "    for i, _ax in enumerate(axs):\n",
    "        if accumulate_returns:\n",
    "            dat_y = np.cumsum(metrics['x'][0][i])\n",
    "            dat_pred = np.cumsum(metrics['pred'][0][i])\n",
    "        else:\n",
    "            dat_y = metrics['x'][0][i]\n",
    "            dat_pred = metrics['pred'][0][i]\n",
    "        _ax.plot(dat_y, label='y target')\n",
    "        _ax.plot(dat_pred, label='pred')\n",
    "        _ax.legend()\n",
    "    return fig, ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size 6345\n",
      "len of train dataset 1502192\n",
      "len of train dataloader 23472\n"
     ]
    }
   ],
   "source": [
    "window_size = 64\n",
    "batch_size = 64\n",
    "d_model = 32\n",
    "encoded_size = 8\n",
    "d_fc = 32\n",
    "encoder_channels = [32, 32]\n",
    "decoder_channels = [64, 64, 64]\n",
    "dropout = 0.2\n",
    "\n",
    "trn_dset = FixedWindow(trn_df, window_size)\n",
    "tst_dset = FixedWindow(tst_df, window_size)\n",
    "trnloader = torch.utils.data.DataLoader(trn_dset, batch_size=batch_size, \n",
    "                                        shuffle=True)\n",
    "tstloader = torch.utils.data.DataLoader(tst_dset, batch_size=batch_size, \n",
    "                                        shuffle=True)\n",
    "\n",
    "# model = AE_MLP(input_size=window_size, encoded_size=16, d_model=64, n_encoding_layers=1).to(device)\n",
    "# model = AE_CNN_SYMM(input_size=window_size, encoded_size=window_size//8,\n",
    "#                     d_model=d_model, d_fc=d_fc, n_encoding_layers=1).to(device)\n",
    "# model = AE_CNN_ASYMM(input_size=64, encoded_size=32, d_model=32, n_encoding_layers=4).to(device)\n",
    "model = AE_CNN(window_size, encoder_channels, encoded_size, \n",
    "               d_fc, decoder_channels, dropout=dropout).to(device)\n",
    "print('model size', model_size(model))\n",
    "print('len of train dataset', len(trn_dset))\n",
    "print('len of train dataloader', len(trnloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test forward pass\n",
    "\n",
    "x = next(iter(trnloader))[0].to(device)\n",
    "pred = model(x)\n",
    "assert x.shape == pred.shape, print(pred.shape, x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f491623fdf4c4f78a99f552ae1f06e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.019935397431254387\n"
     ]
    }
   ],
   "source": [
    "epochs =  1\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "for i in tqdm(range(epochs)):\n",
    "    train_loop = iter(trainer(model, trnloader, device))\n",
    "    for loss in train_loop:\n",
    "        losses.append(loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = test(model, tstloader, device)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].plot(losses[-len(trnloader)+10:])\n",
    "ax[0].plot(pd.Series(losses[-len(trnloader)+10:]).rolling(50).mean(),\n",
    "          label='running mean (50 period)')\n",
    "ax[0].set_title('Training Loss')\n",
    "ax[1].plot(metrics['loss'])\n",
    "ax[1].plot(pd.Series(metrics['loss']).rolling(50).mean(),\n",
    "          label='running mean (50 period)')\n",
    "_ = ax[1].set_title(f\"Val Loss \\nmean: {np.mean(metrics['loss']): .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = show_performance(metrics, accumulate_returns=False)\n",
    "_ = fig.suptitle(f\"Model: {type(model).__name__}  \\n\" +\n",
    "                 f\"mean loss: {np.mean(metrics['loss']): .4f} \\n\" +\n",
    "                 f\"# params: {model_size(model)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AE_CNN(\n",
       "   (dropout): Dropout(p=0.2, inplace=False)\n",
       "   (act): GELU()\n",
       "   (encoder_conv): Sequential(\n",
       "     (0): Conv1d(1, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "     (1): GELU()\n",
       "     (2): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)\n",
       "     (3): GELU()\n",
       "   )\n",
       "   (encoder_fc): Linear(in_features=2048, out_features=8, bias=True)\n",
       "   (decoder_conv): Sequential(\n",
       "     (0): ConvTranspose1d(32, 64, kernel_size=(5,), stride=(1,), groups=2)\n",
       "     (1): GELU()\n",
       "     (2): ConvTranspose1d(64, 64, kernel_size=(5,), stride=(1,), groups=2)\n",
       "     (3): GELU()\n",
       "     (4): ConvTranspose1d(64, 64, kernel_size=(5,), stride=(1,), groups=2)\n",
       "     (5): GELU()\n",
       "     (6): ConvTranspose1d(64, 1, kernel_size=(5,), stride=(1,))\n",
       "   )\n",
       "   (decoder_fc): Linear(in_features=8, out_features=1536, bias=True)\n",
       " ),\n",
       " Dropout(p=0.2, inplace=False),\n",
       " GELU(),\n",
       " Sequential(\n",
       "   (0): Conv1d(1, 32, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "   (1): GELU()\n",
       "   (2): Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,), groups=2)\n",
       "   (3): GELU()\n",
       " ),\n",
       " Conv1d(1, 32, kernel_size=(5,), stride=(1,), padding=(2,)),\n",
       " Conv1d(32, 32, kernel_size=(5,), stride=(1,), padding=(2,), groups=2),\n",
       " Linear(in_features=2048, out_features=8, bias=True),\n",
       " Sequential(\n",
       "   (0): ConvTranspose1d(32, 64, kernel_size=(5,), stride=(1,), groups=2)\n",
       "   (1): GELU()\n",
       "   (2): ConvTranspose1d(64, 64, kernel_size=(5,), stride=(1,), groups=2)\n",
       "   (3): GELU()\n",
       "   (4): ConvTranspose1d(64, 64, kernel_size=(5,), stride=(1,), groups=2)\n",
       "   (5): GELU()\n",
       "   (6): ConvTranspose1d(64, 1, kernel_size=(5,), stride=(1,))\n",
       " ),\n",
       " ConvTranspose1d(32, 64, kernel_size=(5,), stride=(1,), groups=2),\n",
       " ConvTranspose1d(64, 64, kernel_size=(5,), stride=(1,), groups=2),\n",
       " ConvTranspose1d(64, 64, kernel_size=(5,), stride=(1,), groups=2),\n",
       " ConvTranspose1d(64, 1, kernel_size=(5,), stride=(1,)),\n",
       " Linear(in_features=8, out_features=1536, bias=True)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.modules())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
