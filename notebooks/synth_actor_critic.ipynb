{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import math\n",
    "\n",
    "import numba\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from madigan.environments import make_env\n",
    "from madigan.environments.cpp import Broker, Synth, Env as EnvC\n",
    "from madigan.environments.cpp import Assets, RiskInfo, EnvInfoMulti, EnvInfoSingle\n",
    "\n",
    "from madigan.fleet import make_agent\n",
    "\n",
    "from madigan.utils.preprocessor import make_preprocessor as _make_preprocessor\n",
    "from madigan.utils import make_config, State\n",
    "from madigan.utils import ReplayBuffer, SARSD, DiscreteActionSpace\n",
    "from madigan.utils import list_2_dict, reduce_train_metrics\n",
    "\n",
    "\n",
    "from madigan.run.test import test\n",
    "from madigan.utils.plotting import plot_test_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'basepath': '/media/hemu/Data/madigan/experiments',\n",
       " 'experiment_path': '/media/hemu/Data/madigan/experiments/AC',\n",
       " 'experiment_id': 'AC',\n",
       " 'parent_id': '',\n",
       " 'transaction_cost_abs': 0.0,\n",
       " 'transaction_cost_rel': 0.02,\n",
       " 'slippage_abs': 0.0,\n",
       " 'slippage_rel': 0.0,\n",
       " 'env_type': 'Synth',\n",
       " 'init_cash': 1000000,\n",
       " 'required_margin': 1.0,\n",
       " 'maintenance_margin': 0.25,\n",
       " 'assets': ['sine1'],\n",
       " 'lot_unit_value': 10000,\n",
       " 'n_assets': 1,\n",
       " 'discrete_actions': True,\n",
       " 'discrete_action_atoms': 3,\n",
       " 'data_source_type': 'SineAdder',\n",
       " 'data_source_config': {'freq': [2.2, 4.1, 1.0, 3.0],\n",
       "  'mu': [0.6, 0.3, 2.0, 4.2],\n",
       "  'amp': [0.5, 0.2, 0.4, 1.2],\n",
       "  'phase': [0.0, 1.0, 4.0, 0.0],\n",
       "  'dX': 0.01,\n",
       "  'noise': 0.0},\n",
       " 'preprocessor_type': 'RollerDiscrete',\n",
       " 'preprocessor_config': {'timeframes': [64], 'window_length': 64},\n",
       " 'agent_type': 'DQN',\n",
       " 'agent_config': {'type': 'DQN',\n",
       "  'nsteps': 1000000,\n",
       "  'replay_size': 100000,\n",
       "  'episode_length': 1024,\n",
       "  'replay_min_size': 50000,\n",
       "  'train_freq': 4,\n",
       "  'target_update_freq': 32000,\n",
       "  'batch_size': 34,\n",
       "  'discrete_action_atoms': 3,\n",
       "  'double_dqn': True,\n",
       "  'dueling': True,\n",
       "  'iqn': True,\n",
       "  'nTau': 32,\n",
       "  'nTau1': 32,\n",
       "  'nTau2': 8,\n",
       "  'k_huber': 1,\n",
       "  'tau_embed_size': 64,\n",
       "  'discount': 0.999,\n",
       "  'nstep_return': 5,\n",
       "  'action_atoms': 3,\n",
       "  'tau_soft_update': 0.0001,\n",
       "  'greedy_eps_testing': 0.0,\n",
       "  'eps': 1.0,\n",
       "  'eps_min': 0.1,\n",
       "  'eps_decay': 0.999999,\n",
       "  'reward_clip': (-1.0, 1.0),\n",
       "  'unit_size_proportion_avM': 0.05},\n",
       " 'model_config': {'model_class': 'ConvNet',\n",
       "  'd_model': 1024,\n",
       "  'n_layers': 4,\n",
       "  'n_feats': 1,\n",
       "  'action_atoms': 3,\n",
       "  'n_assets': 1,\n",
       "  'dueling': True,\n",
       "  'iqn': True,\n",
       "  'nTau': 32,\n",
       "  'nTau1': 32,\n",
       "  'nTau2': 8,\n",
       "  'tau_embed_size': 64,\n",
       "  'discrete_actions': True,\n",
       "  'discrete_action_atoms': 3,\n",
       "  'lot_unit_value': 10000},\n",
       " 'optim_config': {'type': 'Adam',\n",
       "  'lr': 0.001,\n",
       "  'lr_critic': 0.001,\n",
       "  'lr_actor': 0.0001,\n",
       "  'eps': 1e-08,\n",
       "  'momentum': 0.9,\n",
       "  'betas': (0.9, 0.999),\n",
       "  'weight_decay': 0},\n",
       " 'train_steps': 100000,\n",
       " 'reward_clip': (-1.0, 1.0),\n",
       " 'test_steps': 1000,\n",
       " 'test_freq': 32000,\n",
       " 'log_freq': 10000,\n",
       " 'model_save_freq': 64000}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = make_config(\n",
    "        experiment_id=\"AC\",\n",
    "        basepath=\"/media/hemu/Data/madigan/experiments\",\n",
    "    \n",
    "    \n",
    "        transaction_cost_rel=0.02,\n",
    "    \n",
    "        test_steps=1_000,\n",
    "        nsteps=1_000_000,\n",
    "    \n",
    "#         data_source_type=\"Triangle\",\n",
    "#         generator_params={\n",
    "#         'freq':[2.],\n",
    "#         'mu':[0.6],\n",
    "#         'amp':[.5],\n",
    "#         'phase':[0.],\n",
    "#         'dX':0.1,\n",
    "#         \"noise\": 0.0},\n",
    "        assets=[\"sine1\"],\n",
    "        data_source_type=\"SineAdder\",\n",
    "        data_source_config={\n",
    "            'freq':[2.2, 4.1, 1., 3.],\n",
    "            'mu':[.6, 0.3, 2., 4.2],\n",
    "            'amp':[.5, 0.2, 0.4, 1.2],\n",
    "            'phase':[0., 1., 4., 0.],\n",
    "            'dX':0.01,\n",
    "            \"noise\": 0.0},\n",
    "#         assets=[\"OU1\"],\n",
    "#         data_source_type=\"OU\",\n",
    "#         data_source_config=dict(\n",
    "#             mean=[10.],\n",
    "#             theta=[.15],\n",
    "#             phi = [4.],\n",
    "#             noise_var = [.1]\n",
    "#         ),\n",
    "#         assets=[\"trend1\"],\n",
    "#         data_source_type=\"SimpleTrend\",\n",
    "#         data_source_config=dict(\n",
    "#             trend_prob=[.001],\n",
    "#             min_period=[500],\n",
    "#             max_period=[1500],\n",
    "#             noise = [.1],\n",
    "#             dY = [0.001],\n",
    "#             start = [5.0]),\n",
    "        preprocessor_type=\"RollerDiscrete\",\n",
    "        preprocessor_config=dict(\n",
    "#             timeframes = [64, 128, 512],\n",
    "            timeframes=[64],\n",
    "            window_length = 64,\n",
    "        ),\n",
    "    \n",
    "        agent_type = \"DQN\",\n",
    "        discrete_actions=True,\n",
    "        discrete_action_atoms=3,\n",
    "        double_dqn=True,\n",
    "        dueling=True,\n",
    "        iqn=True,\n",
    "        nTau1=32,\n",
    "        nTau2=8,\n",
    "        k_huber=1,\n",
    "        nstep_return = 5,\n",
    "        tau_soft_update=1e-4,\n",
    "        replay_size=100_000,\n",
    "        replay_min_size=50_000,\n",
    "        batch_size=34,\n",
    "        discount = 0.999,\n",
    "        lot_unit_value=10_000,\n",
    "        unit_size_proportion_avM=0.05,\n",
    "    \n",
    "        expl_eps_decay=0.999999,\n",
    "    \n",
    "        model_class=\"ConvNet\",\n",
    "        d_model = 1024,\n",
    "        lr=1e-3,\n",
    "\n",
    "    )\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.5901912 ,  1.38107436,  1.59809249,  0.69865719,  0.86003156,\n",
       "        -1.73803073, -0.36762804, -0.50307311,  1.24544295,  0.39380454]),\n",
       " array([ 1.,  1.,  1.,  1.,  1., -1., -1., -1.,  1.,  1.]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@numba.njit\n",
    "def ternarize_array(arr):\n",
    "    out = np.empty_like(arr)\n",
    "    out[arr<0.] = -1.\n",
    "    out[arr==0.] = 0.\n",
    "    out[arr>0.] = 1.\n",
    "    return out\n",
    "# test\n",
    "ara = np.random.randn(10)\n",
    "out = ternarize_array(ara)\n",
    "ara, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.23253571],\n",
       "        [ 1.34693722],\n",
       "        [ 0.45423326],\n",
       "        [ 1.74249611],\n",
       "        [ 0.53727901],\n",
       "        [-0.36116556],\n",
       "        [ 1.51764352],\n",
       "        [-0.19463558],\n",
       "        [-0.58550164],\n",
       "        [-0.88554128]]),\n",
       " array([[ 1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [ 1.],\n",
       "        [-1.],\n",
       "        [ 1.],\n",
       "        [-1.],\n",
       "        [-1.],\n",
       "        [-1.]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# @numba.vectorize([numba.int32(numba.int32),\n",
    "#                   numba.int64(numba.int64),\n",
    "#                   numba.float32(numba.float32),\n",
    "#                   numba.float64(numba.float64)])\n",
    "\n",
    "@numba.vectorize([numba.float32(numba.float32),\n",
    "                  numba.float64(numba.float64)])\n",
    "def ternarize_array(val):\n",
    "    if val < 0:\n",
    "        out = -1.\n",
    "    elif val > 0.:\n",
    "        out = 1.\n",
    "    else:\n",
    "        out = 0.\n",
    "    return out\n",
    "# test\n",
    "ara = np.random.randn(10, 1)\n",
    "out = ternarize_array(ara)\n",
    "ara, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     3,
     13
    ]
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class BrokerResponse:\n",
    "    event: str\n",
    "    timestamp: int\n",
    "    transPrice: float\n",
    "    transUnits: float\n",
    "    transCost: float\n",
    "    riskInfo: object\n",
    "    marginCall: bool\n",
    "\n",
    "@dataclass\n",
    "class EnvInfo:\n",
    "    brokerResponse: BrokerResponse\n",
    "    exiting: bool\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class EnvTernary(EnvC):\n",
    "    def step(self, actions: np.ndarray = None):\n",
    "        \"\"\"\n",
    "        If actions is None, no transaction is attempted and dataSource is iterated to\n",
    "        get new prices\n",
    "        If actions is passed, a transaction/s is attempted. Can only Reverse Positions, not add to \n",
    "        or close.\n",
    "        Hence EnvBinary.\n",
    "        \"\"\"\n",
    "\n",
    "        if actions is None: # no transaction\n",
    "            prevEq = self.portfolio.equity\n",
    "            newPrices = self.dataSource.getData()\n",
    "            newEq = self.portfolio.equity\n",
    "            reward = (newEq-prevEq) / prevEq\n",
    "            risk = self.portfolio.checkRisk()\n",
    "            done = False if risk == RiskInfo.green else True\n",
    "\n",
    "            return (State(newPrices, np.array(self.ledgerNormed, copy=True),\n",
    "                          self.dataSource.currentTime),\n",
    "                    reward, done, EnvInfo(BrokerResponse(\"\", 0, 0., 0., 0., \n",
    "                                                             risk, done), False))\n",
    "        else:\n",
    "            if not isinstance(actions, np.ndarray):\n",
    "                raise TypeError(\"action must be an np array\")\n",
    "\n",
    "            prevEq = self.portfolio.equity\n",
    "            newPrices = self.dataSource.getData()\n",
    "            newEq = self.portfolio.equity\n",
    "            reward = newEq / prevEq \n",
    "            reward = math.log(max(reward, 0.3))\n",
    "\n",
    "            ledger_ternary = self.ledgerTernary\n",
    "            actions_ternary = actions - 1\n",
    "#             actions_ternary[ledger_ternary == actions_ternary] = 0.\n",
    "            units = (0.2*self.availableMargin) / self.currentPrices\n",
    "            transactions = actions_ternary * units\n",
    "\n",
    "#             exiting = False\n",
    "            assets = np.where(transactions!=0.)[0]\n",
    "            for i, asset in enumerate(assets): # implicit if len(assets)\n",
    "                reward -= self.transaction_cost_rel\n",
    "#                 if self.ledger[i] != 0:\n",
    "#                     exiting = True\n",
    "#                     self.broker.close(int(asset))\n",
    "                    \n",
    "            broker_response_multi = self.broker.handleTransaction(transactions)\n",
    "            \n",
    "            done = False\n",
    "            if broker_response_multi.marginCall:\n",
    "                done=True\n",
    "            for _risk in broker_response_multi.riskInfo:\n",
    "                if _risk != RiskInfo.green:\n",
    "                    done = True\n",
    "#             if exiting:\n",
    "#                 done = True\n",
    "            if self.equity < 0.1 * self.portfolio.initCash:\n",
    "                done = True\n",
    "                print('equity: ', self.equity)\n",
    "\n",
    "            return (State(newPrices, np.array(self.ledgerNormed, copy=True),\n",
    "                          self.dataSource.currentTime),\n",
    "                    reward, done, EnvInfo(broker_response_multi, 0.))\n",
    "\n",
    "    @property\n",
    "    def ledgerTernary(self):\n",
    "        ara = np.array(self.ledger, copy=True)\n",
    "        return ternarize_array(ara)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# def make_env(config):\n",
    "#     assets = Assets(config.assets)\n",
    "#     env = EnvTernary(config.data_source_type, assets, config.init_cash, config)\n",
    "#     env.lot_unit = config.lot_unit_value\n",
    "#     env.action_atoms = config.discrete_action_atoms\n",
    "#     env.transaction_cost_rel = config.transaction_cost_rel\n",
    "# #     env.setTransactionCost\n",
    "#     return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward: 0.0\n",
      "reward: 0.0033655405894050697\n",
      "[7.21755705] 1000000.0 1000000.0 [0.] 1000000.0\n"
     ]
    }
   ],
   "source": [
    "env = make_env(config)\n",
    "srdi = env.step(np.array([10000]))\n",
    "print('reward:', srdi[1])\n",
    "print('reward:', env.step()[1])\n",
    "env.step(np.array([0]))\n",
    "env.reset()\n",
    "print(env.currentPrices, env.cash, env.equity, env.ledger, env.availableMargin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1514.77390854])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srdi[3].brokerResponse.transactionCost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import sklearn.preprocessing\n",
    "\n",
    "class Preprocessor:\n",
    "    def __init__(self, window_len):\n",
    "        self.k = window_len\n",
    "        self.min_tf = self.k\n",
    "        self.price_buffer = deque(maxlen=self.k)\n",
    "        self.portfolio_buffer = deque(maxlen=self.k)\n",
    "        self.time_buffer = deque(maxlen=self.k)\n",
    "        self.feature_output_size = 12\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.price_buffer)\n",
    "\n",
    "    def stream_srdi(self, srdi):\n",
    "        self.price_buffer.append(srdi[0].price)\n",
    "        self.portfolio_buffer.append(srdi[0].portfolio)\n",
    "        self.time_buffer.append(srdi[0].timestamp)\n",
    "\n",
    "    def stream_state(self, state):\n",
    "        self.price_buffer.append(np.array(state.price, copy=True))\n",
    "        self.portfolio_buffer.append(np.array(state.portfolio, copy=True))\n",
    "        self.time_buffer.append(np.array(state.timestamp, copy=True))\n",
    "\n",
    "    def stream(self, data):\n",
    "        if isinstance(data, tuple): # assume srdi\n",
    "            self.stream_srdi(data)\n",
    "        elif isinstance(data, (StateA, State)):\n",
    "            self.stream_state(data)\n",
    "\n",
    "    def current_data(self):\n",
    "        prices = np.array(self.price_buffer, copy=True)\n",
    "        prices = sklearn.preprocessing.minmax_scale(prices)\n",
    "        features = np.empty(self.feature_output_size)\n",
    "        for i, window in enumerate([3, 5, 7, 11]):\n",
    "            features[i] = np.mean(prices[-window:])\n",
    "            features[i+4] = np.var(prices[-window:])\n",
    "        features[8] = prices.min()\n",
    "        features[9] = prices.max()\n",
    "        features[10] = prices[0]\n",
    "        features[11] = prices[-1]\n",
    "        return State(features.reshape(-1, 1) ,\n",
    "                     self.portfolio_buffer[-1],\n",
    "                     self.time_buffer[-1])\n",
    "\n",
    "    def initialize_history(self, env):\n",
    "        while len(self) < self.k:\n",
    "            _state, reward, done, info = env.step()\n",
    "            self.stream_state(_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_preprocessor(config):\n",
    "    if config.preprocessor_type == \"Custom\":\n",
    "        return Preprocessor(config.preprocessor_config.window_length)\n",
    "    return _make_preprocessor(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<madigan.environments.cpp.build.env.State at 0x7fce9066aeb0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.pylabtools import figsize\n",
    "figsize(8, 6)\n",
    "\n",
    "preprocessor = make_preprocessor(config)\n",
    "env.currentPrices\n",
    "preprocessor.initialize_history(env)\n",
    "plt.plot(preprocessor.current_data().price)\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1920928955078125e-07"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps = np.finfo(np.float32).eps.item(); eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpisodeBuffer:\n",
    "    def __init__(self, episode_length, nstep_return, discount):\n",
    "        self.episode_length = episode_length\n",
    "        self.nstep_return = nstep_return\n",
    "        self.discount = discount\n",
    "        self.states = torch.empty()\n",
    "    def append(self, state, action, reward, next_state, done, logp):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [
     0,
     36
    ]
   },
   "outputs": [],
   "source": [
    "class ConvActor(nn.Module):\n",
    "    def __init__(self, config, feature_input_size):\n",
    "        super().__init__()\n",
    "        nassets = len(config.assets)\n",
    "        d_model = config.agent_config.model_config.d_model\n",
    "        nactions = config.discrete_action_atoms\n",
    "        self.conv1 = nn.Conv1d(1, 32, 5)\n",
    "        self.conv2 = nn.Conv1d(32, 32, 5)\n",
    "        out_shape = calc_conv_out_shape(feature_input_size, [self.conv1, self.conv2])\n",
    "        self.fc1 = nn.Linear(nassets+out_shape[0]*32, d_model)\n",
    "        self.dropout = nn.Dropout(0.6)\n",
    "        self.policy_head = nn.Linear(d_model, 3)\n",
    "        self.act = nn.GELU()     \n",
    "    \n",
    "    def forward(self, state):\n",
    "        state_emb = self.get_state_emb(state)\n",
    "        policy_probs = self.get_policy_probs(state_emb=state_emb)\n",
    "        return policy_probs\n",
    "    \n",
    "    def get_state_emb(self, state):\n",
    "        price = state.price.transpose(-1, -2)\n",
    "        portfolio = state.portfolio\n",
    "        price_emb = self.act(self.conv1(price))\n",
    "        price_emb = self.act(self.conv2(price_emb)).view(price.shape[0], -1)\n",
    "        full_emb = torch.cat([price_emb, portfolio], dim=-1)\n",
    "        full_emb = self.act(self.fc1(full_emb))\n",
    "        return self.dropout(full_emb)\n",
    "        \n",
    "    def get_policy_probs(self, state=None, state_emb=None):\n",
    "        assert state is not None or state_emb is not None\n",
    "        if state_emb is None:\n",
    "            state_emb = self.get_state_emb(state)\n",
    "        probs = F.softmax(self.policy_head(state_emb), dim=-1)\n",
    "        return probs\n",
    "\n",
    "    \n",
    "class Actor_CNN:\n",
    "    \"\"\" Reinforce \"\"\"\n",
    "    def __init__(self, config, feature_input_size, env, device=None):\n",
    "        self.device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self._env = env\n",
    "        \n",
    "        self.action_atoms = config.discrete_action_atoms\n",
    "\n",
    "        self.lot_unit_value = config.lot_unit_value\n",
    "        actions = [self.lot_unit_value*action - self.action_atoms//2 for action in range(self.action_atoms)]\n",
    "        probs = [1/len(actions) for i in actions]\n",
    "        self._action_space = DiscreteRangeSpace((0, 2), len(config.assets))\n",
    "\n",
    "        self.model = ConvActor(config, feature_input_size).to(self.device)\n",
    "        self.episode_buffer = [] # (state, logp)\n",
    "#         self.episode_actions = []\n",
    "        \n",
    "        self.discount = config.agent_config.discount\n",
    "        self.nstep_return = config.nstep_return\n",
    "        self.opt = torch.optim.Adam(self.model.parameters(),\n",
    "                                    lr=config.agent_config.optim_config.lr)\n",
    "        \n",
    "        self.config = config\n",
    "        self.nassets = len(config.assets)\n",
    "        self.logp_mem = []\n",
    "        self.return_mem = []\n",
    "        #         self.dueling = config.agent_config.model_config.dueling\n",
    "#         self.double_dqn = config.agent_config.double_dqn\n",
    "#         self.tau_soft_update = config.agent_config.tau_soft_update\n",
    "        \n",
    "    @property\n",
    "    def env(self):\n",
    "        return self._env\n",
    "    \n",
    "    @property\n",
    "    def action_space(self):\n",
    "        return self._action_space\n",
    "    \n",
    "    def prep_state(self, state, batch=False):\n",
    "        if not batch:\n",
    "            price = torch.as_tensor(state.price[None, ...], dtype=torch.float32).to(self.device)\n",
    "            port = torch.as_tensor(state.portfolio[None, -1], dtype=torch.float32).to(self.device)\n",
    "        else:\n",
    "            price = torch.as_tensor(state.price, dtype=torch.float32).to(self.device)\n",
    "            port = torch.as_tensor(state.portfolio[:, -1], dtype=torch.float32).to(self.device)\n",
    "#         timestamp = torch.as_tensor(state.timestamp)\n",
    "        return State(price, port, state.timestamp)\n",
    "    \n",
    "    \n",
    "    def get_policy(self, state):\n",
    "        state = self.prep_state(state)\n",
    "        probs = self.model.get_policy_probs(state)\n",
    "        return Categorical(probs)\n",
    "    \n",
    "    def get_action(self, state):\n",
    "        policy = self.get_policy(state)\n",
    "        action = policy.sample(sample_shape=(self.nassets, ))[:, 0]\n",
    "        self.logp_mem.append(policy.log_prob(action))\n",
    "        return self.action_to_transaction(action)\n",
    "    \n",
    "    def action_to_transaction(self, actions):\n",
    "        units = 0.1 * self.env.availableMargin / self.env.currentPrices\n",
    "        actions_ternary = (actions - (self.action_atoms // 2)).cpu().numpy()\n",
    "        return units * actions_ternary\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def __call__(self, state):\n",
    "        policy = self.get_policy(state)\n",
    "        actions = policy.sample()\n",
    "        return self.action_to_transaction(actions)\n",
    "        \n",
    "    def prep_sarsd(self, sarsd):\n",
    "        state = self.prep_state(sarsd.state, batch=True)\n",
    "#         action = np.rint(sarsd.action // self.lot_unit_value) + self.action_atoms//2\n",
    "        action = ternarize_array(sarsd.action) + self.action_atoms // 2\n",
    "        action = torch.as_tensor(action, dtype=torch.long, device=self.device)[..., 0]\n",
    "        reward = torch.as_tensor(sarsd.reward, dtype=torch.float32, device=self.device)\n",
    "        next_state = self.prep_state(sarsd.next_state, batch=True)\n",
    "        done = torch.as_tensor(sarsd.done, dtype=torch.bool, device=self.device)\n",
    "        return state, action, reward, next_state, done\n",
    "    \n",
    "    def loss_fn(self, Qt, Gt):\n",
    "        return F.smooth_l1_loss(Qt, Gt)\n",
    "    \n",
    "    def train_step(self, sarsd):\n",
    "#         state, action, reward, next_state, done = self.prep_sarsd(sarsd)\n",
    "        R = 0    \n",
    "        returns = []\n",
    "        for r in self.return_mem[::-1]:\n",
    "            R = r + self.discount * R\n",
    "            returns.append(R)\n",
    "        returns.reverse()\n",
    "        returns = torch.tensor(returns).to(self.device)\n",
    "        returns = (returns - returns.mean()) / (returns.std() + eps)\n",
    "        policy_loss = []\n",
    "        for logp, R in zip(self.logp_mem, returns):\n",
    "            policy_loss.append(-logp * R)\n",
    "        \n",
    "        policy_loss = torch.cat(policy_loss).sum()\n",
    "#         logp = torch.stack(self.logp_mem).squeeze()\n",
    "#         actor_loss = -(logp * returns).sum()\n",
    "        loss = policy_loss\n",
    "    \n",
    "        self.opt.zero_grad()\n",
    "        loss.backward()\n",
    "        self.opt.step()\n",
    "        self.logp_mem.clear()\n",
    "        self.return_mem.clear()\n",
    "                        \n",
    "        return {'loss': loss.detach().item(), \n",
    "                'return': returns.mean().detach().item(),\n",
    "                'logp': logp.mean().detach().item()}    \n",
    "     \n",
    "    def train(self):\n",
    "        self.model.train()\n",
    "    def eval(self):\n",
    "        self.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpisodeBuffer:\n",
    "    def __init__(self, size):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": [
     5
    ]
   },
   "outputs": [],
   "source": [
    "from torch.distributions import Categorical\n",
    "from madigan.utils import DiscreteRangeSpace, DiscreteActionSpace\n",
    "import torch.nn.functional as F\n",
    "from madigan.utils import calc_conv_out_shape\n",
    "    \n",
    "class ConvActorCritic(nn.Module):\n",
    "    def __init__(self, config, feature_input_shape):\n",
    "        super().__init__()\n",
    "        nassets = len(config.assets)\n",
    "        d_model = config.model_config.d_model\n",
    "        nactions = config.discrete_action_atoms\n",
    "        self.conv1 = nn.Conv1d(feature_input_shape[1], 32, 5)\n",
    "        self.conv2 = nn.Conv1d(32, 32, 5)\n",
    "        out_shape = calc_conv_out_shape(feature_input_shape[0],\n",
    "                                        [self.conv1, self.conv2])\n",
    "        self.fc1 = nn.Linear(nassets+out_shape[0]*32, d_model)\n",
    "        self.value_head = nn.Linear(d_model, 1)\n",
    "        self.policy_head = nn.Linear(d_model, 3)\n",
    "        self.act = nn.GELU()     \n",
    "    \n",
    "    def forward(self, state):\n",
    "        state_emb = self.get_state_emb(state)\n",
    "        policy_probs = self.get_policy_probs(state_emb=state_emb)\n",
    "        value = self.get_state_value(state_emb=state_emb)\n",
    "        return policy_probs, value\n",
    "    \n",
    "    def get_state_emb(self, state):\n",
    "        price = state.price.transpose(-1, -2)\n",
    "        portfolio = state.portfolio\n",
    "        price_emb = self.act(self.conv1(price))\n",
    "        price_emb = self.act(self.conv2(price_emb)).view(price.shape[0], -1)\n",
    "        full_emb = torch.cat([price_emb, portfolio], dim=-1)\n",
    "        full_emb = self.act(self.fc1(full_emb))\n",
    "        return nn.Dropout(0.5)(full_emb)\n",
    "        \n",
    "    def get_policy_probs(self, state=None, state_emb=None):\n",
    "        assert state is not None or state_emb is not None\n",
    "        if state_emb is None:\n",
    "            state_emb = self.get_state_emb(state)\n",
    "        probs = F.softmax(self.policy_head(state_emb), dim=-1)\n",
    "        return probs\n",
    "    \n",
    "    def get_state_value(self, state=None, state_emb=None):\n",
    "        assert state is not None or state_emb is not None\n",
    "        if state_emb is None:\n",
    "            state_emb = self.get_state_emb(state)\n",
    "        value = self.value_head(state_emb)\n",
    "        return value\n",
    "    \n",
    "class ActorCritic_CNN:\n",
    "    def __init__(self, config, feature_input_shape, env, device=None):\n",
    "        self.device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self._env = env\n",
    "        \n",
    "        self.action_atoms = config.discrete_action_atoms\n",
    "        self.lot_unit_value = config.lot_unit_value\n",
    "        actions = [self.lot_unit_value*action - self.action_atoms//2 for action in range(self.action_atoms)]\n",
    "        probs = [1/len(actions) for i in actions]\n",
    "        self._action_space = DiscreteRangeSpace((0, 2), len(config.assets))\n",
    "\n",
    "        self.model = ConvActorCritic(config, feature_input_shape).to(self.device)\n",
    "        self.episode_buffer = [] # (state, logp)\n",
    "#         self.episode_actions = []\n",
    "        \n",
    "        self.discount = config.agent_config.discount\n",
    "        self.nstep_return = config.agent_config.nstep_return\n",
    "        self.opt = torch.optim.Adam(self.model.parameters(),\n",
    "                                    lr=config.optim_config.lr)\n",
    "        \n",
    "        self.config = config\n",
    "        self.nassets = len(config.assets)\n",
    "        self.logp_mem = []\n",
    "        self.state_val_mem = []\n",
    "        self.return_mem = []\n",
    "        #         self.dueling = config.agent_config.model_config.dueling\n",
    "#         self.double_dqn = config.agent_config.double_dqn\n",
    "#         self.tau_soft_update = config.agent_config.tau_soft_update\n",
    "        \n",
    "    @property\n",
    "    def env(self):\n",
    "        return self._env\n",
    "    \n",
    "    @property\n",
    "    def action_space(self):\n",
    "        return self._action_space\n",
    "    \n",
    "    def prep_state(self, state, batch=False):\n",
    "        if not batch:\n",
    "            price = torch.as_tensor(state.price[None, ...], dtype=torch.float32).to(self.device)\n",
    "            port = torch.as_tensor(state.portfolio[None, -1], dtype=torch.float32).to(self.device)\n",
    "        else:\n",
    "            price = torch.as_tensor(state.price, dtype=torch.float32).to(self.device)\n",
    "            port = torch.as_tensor(state.portfolio[:, -1], dtype=torch.float32).to(self.device)\n",
    "#         timestamp = torch.as_tensor(state.timestamp)\n",
    "        return State(price, port, state.timestamp)\n",
    "    \n",
    "    def get_state_value(self, state, target=False):\n",
    "        state = self.prep_state(state)\n",
    "        state_vals = self.model.get_state_value(state)\n",
    "        return state_vals\n",
    "    \n",
    "    def get_policy(self, state):\n",
    "        state = self.prep_state(state)\n",
    "        probs = self.model.get_policy_probs(state)\n",
    "        return Categorical(probs)\n",
    "    \n",
    "    def get_action(self, state):\n",
    "        state = self.prep_state(state)\n",
    "        probs, state_val = self.model(state)\n",
    "        policy = Categorical(probs)\n",
    "        action = policy.sample(sample_shape=(self.nassets, ))[:, 0]\n",
    "#         self.episode_memory.append((\n",
    "#             state, policy.log_prob(action))\n",
    "#         )\n",
    "        self.logp_mem.append(policy.log_prob(action))\n",
    "        self.state_val_mem.append(state_val)\n",
    "        return self.action_to_transaction(action)\n",
    "    \n",
    "    def action_to_transaction(self, actions):\n",
    "        units = 0.1 * self.env.availableMargin / self.env.currentPrices\n",
    "        actions_ternary = (actions - (self.action_atoms // 2)).cpu().numpy()\n",
    "        return units * actions_ternary\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def __call__(self, state):\n",
    "        policy = self.get_policy(state)\n",
    "        actions = policy.sample()\n",
    "        return self.action_to_transaction(actions)\n",
    "        \n",
    "    def prep_sarsd(self, sarsd):\n",
    "        state = self.prep_state(sarsd.state, batch=True)\n",
    "#         action = np.rint(sarsd.action // self.lot_unit_value) + self.action_atoms//2\n",
    "        action = ternarize_array(sarsd.action) + self.action_atoms // 2\n",
    "        action = torch.as_tensor(action, dtype=torch.long, device=self.device)[..., 0]\n",
    "        reward = torch.as_tensor(sarsd.reward, dtype=torch.float32, device=self.device)\n",
    "        next_state = self.prep_state(sarsd.next_state, batch=True)\n",
    "        done = torch.as_tensor(sarsd.done, dtype=torch.bool, device=self.device)\n",
    "        return state, action, reward, next_state, done\n",
    "    \n",
    "    def loss_fn(self, Qt, Gt):\n",
    "        return F.smooth_l1_loss(Qt, Gt)\n",
    "    \n",
    "    def train_step(self, sarsd):\n",
    "        state, action, reward, next_state, done = self.prep_sarsd(sarsd)\n",
    "        \n",
    "        critic_target = reward.squeeze()\n",
    "        \n",
    "        state_emb = self.model.get_state_emb(state)\n",
    "        state_val = torch.stack(self.state_val_mem).squeeze()\n",
    "        adv = critic_target - state_val # aka td_error\n",
    "        logp = torch.stack(self.logp_mem)\n",
    "\n",
    "        actor_loss = -(logp * adv).sum()\n",
    "        critic_loss = F.smooth_l1_loss(state_val, critic_target)\n",
    "        loss = actor_loss + critic_loss \n",
    "    \n",
    "        self.opt.zero_grad()\n",
    "        loss.backward()\n",
    "        self.opt.step()\n",
    "        self.logp_mem.clear()\n",
    "        self.state_val_mem.clear()\n",
    "#         self.episode_logp.clear()\n",
    "                        \n",
    "        return {'loss': loss.detach().item(), \n",
    "                'td_error': adv.abs().mean().detach().item(), \n",
    "                'state_val': state_val.mean().detach().item(), \n",
    "                'return': critic_target.mean().detach().item(),\n",
    "                'adv': adv.mean().detach().item()}\n",
    "    \n",
    "    def update_target(self):\n",
    "        \"\"\"\n",
    "        Soft Update \n",
    "        \"\"\"\n",
    "        for behaviour, target in zip(self.critic_b.parameters(), self.critic_t.parameters()):\n",
    "            target.data.copy_(self.tau_soft_update * behaviour.data + \\\n",
    "                              (1.-self.tau_soft_update)*target.data)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state val:  tensor([[0.0299]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
      "policy probs: tensor([[0.3374, 0.3420, 0.3206]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "action:  tensor([0], device='cuda:0')\n",
      "transaction:  [-13855.10350675]\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "agent = ActorCritic_CNN(config, preprocessor.feature_output_shape, env, device=device)\n",
    "# agent = Actor_CNN(config, preprocessor.feature_output_size, env, device=device)\n",
    "\n",
    "state = preprocessor.current_data()\n",
    "# x = agent.prep_state(x)\n",
    "state_val = agent.get_state_value(state)\n",
    "policy = agent.get_policy(state)\n",
    "action = policy.sample()\n",
    "transaction = agent.action_to_transaction(action)\n",
    "print('state val: ', state_val)\n",
    "print('policy probs:', policy.probs) \n",
    "print('action: ', action) \n",
    "print('transaction: ',transaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = agent.prep_state(state)\n",
    "probs = agent.model.get_policy_probs(x)\n",
    "policy = Categorical(probs)\n",
    "action = policy.sample().detach().cpu().numpy()\n",
    "new_policy = Categorical(agent.model.get_policy_probs(x))\n",
    "action = torch.tensor(action).to(device)\n",
    "loss = -new_policy.log_prob(action)\n",
    "\n",
    "loss.backward()\n",
    "# list(p.grad for p in agent.model.policy_head.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [
     19
    ]
   },
   "outputs": [],
   "source": [
    "def trainer(agent, env, preprocessor, config, episode_length=1024):\n",
    "    episode_buffer = ReplayBuffer(episode_length, \n",
    "                                  nstep_return=config.agent_config.nstep_return,\n",
    "                                 discount=config.agent_config.discount)\n",
    "    eb = episode_buffer\n",
    "\n",
    "    env.reset()\n",
    "    preprocessor.initialize_history(env)\n",
    "    state = preprocessor.current_data()\n",
    "    i = 0\n",
    "    episode_step = 0\n",
    "    running_reward = 0.\n",
    "    running_cost = 0.\n",
    "#     agent.train()\n",
    "    while True:\n",
    "        train_metrics = None\n",
    "        actions = agent.get_action(state)\n",
    "        _next_state, reward, done, info = env.step(actions)\n",
    "        \n",
    "        for cost in info.brokerResponse.transactionCost:\n",
    "            running_cost += cost\n",
    "#         reward = max(-1., min(reward, 1.))\n",
    "        preprocessor.stream_state(_next_state)\n",
    "        next_state = preprocessor.current_data()\n",
    "        if done:\n",
    "            reward = -0.5\n",
    "        agent.return_mem.append(reward)\n",
    "        running_reward += reward\n",
    "        sarsd = SARSD(state, actions, reward, next_state, done)\n",
    "        episode_buffer.add(sarsd)      \n",
    "\n",
    "        if episode_step >= episode_length or done:\n",
    "            sarsd = episode_buffer.get_full()\n",
    "            train_metrics = agent.train_step(sarsd)\n",
    "            train_metrics['running_reward'] = running_reward  \n",
    "            if done:\n",
    "                print('stopped at: ', episode_step, 'steps')\n",
    "                print('equity: ', env.equity, 'margin call: ', info.brokerResponse.marginCall)\n",
    "\n",
    "            print('running_reward: ', running_reward, 'running_cost: ', running_cost)    \n",
    "                \n",
    "            running_reward = 0.\n",
    "            running_cost = 0.\n",
    "            episode_step = 0\n",
    "            episode_buffer.clear()\n",
    "            \n",
    "        if done:\n",
    "            env.reset()\n",
    "            preprocessor.initialize_history(env)\n",
    "            state = preprocessor.current_data()\n",
    "            done = False\n",
    "            \n",
    "        else:\n",
    "            state = next_state\n",
    "            episode_step += 1\n",
    "            \n",
    "        yield train_metrics\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'basepath': '/media/hemu/Data/madigan/experiments',\n",
       " 'experiment_path': '/media/hemu/Data/madigan/experiments/AC',\n",
       " 'experiment_id': 'AC',\n",
       " 'parent_id': '',\n",
       " 'transaction_cost_abs': 0.0,\n",
       " 'transaction_cost_rel': 0.02,\n",
       " 'slippage_abs': 0.0,\n",
       " 'slippage_rel': 0.0,\n",
       " 'env_type': 'Synth',\n",
       " 'init_cash': 1000000,\n",
       " 'required_margin': 1.0,\n",
       " 'maintenance_margin': 0.25,\n",
       " 'assets': ['sine1'],\n",
       " 'lot_unit_value': 10000,\n",
       " 'n_assets': 1,\n",
       " 'discrete_actions': True,\n",
       " 'discrete_action_atoms': 3,\n",
       " 'data_source_type': 'SineAdder',\n",
       " 'data_source_config': {'freq': [2.2, 4.1, 1.0, 3.0],\n",
       "  'mu': [0.6, 0.3, 2.0, 4.2],\n",
       "  'amp': [0.5, 0.2, 0.4, 1.2],\n",
       "  'phase': [0.0, 1.0, 4.0, 0.0],\n",
       "  'dX': 0.01,\n",
       "  'noise': 0.0},\n",
       " 'preprocessor_type': 'RollerDiscrete',\n",
       " 'preprocessor_config': {'timeframes': [64], 'window_length': 64},\n",
       " 'agent_type': 'DQN',\n",
       " 'agent_config': {'type': 'DQN',\n",
       "  'nsteps': 1000000,\n",
       "  'replay_size': 100000,\n",
       "  'episode_length': 1024,\n",
       "  'replay_min_size': 50000,\n",
       "  'train_freq': 4,\n",
       "  'target_update_freq': 32000,\n",
       "  'batch_size': 34,\n",
       "  'discrete_action_atoms': 3,\n",
       "  'double_dqn': True,\n",
       "  'dueling': True,\n",
       "  'iqn': True,\n",
       "  'nTau': 32,\n",
       "  'nTau1': 32,\n",
       "  'nTau2': 8,\n",
       "  'k_huber': 1,\n",
       "  'tau_embed_size': 64,\n",
       "  'discount': 0.999,\n",
       "  'nstep_return': 5,\n",
       "  'action_atoms': 3,\n",
       "  'tau_soft_update': 0.0001,\n",
       "  'greedy_eps_testing': 0.0,\n",
       "  'eps': 1.0,\n",
       "  'eps_min': 0.1,\n",
       "  'eps_decay': 0.999999,\n",
       "  'reward_clip': (-1.0, 1.0),\n",
       "  'unit_size_proportion_avM': 0.05},\n",
       " 'model_config': {'model_class': 'ConvNet',\n",
       "  'd_model': 1024,\n",
       "  'n_layers': 4,\n",
       "  'n_feats': 1,\n",
       "  'action_atoms': 3,\n",
       "  'n_assets': 1,\n",
       "  'dueling': True,\n",
       "  'iqn': True,\n",
       "  'nTau': 32,\n",
       "  'nTau1': 32,\n",
       "  'nTau2': 8,\n",
       "  'tau_embed_size': 64,\n",
       "  'discrete_actions': True,\n",
       "  'discrete_action_atoms': 3,\n",
       "  'lot_unit_value': 10000},\n",
       " 'optim_config': {'type': 'Adam',\n",
       "  'lr': 1e-05,\n",
       "  'lr_critic': 0.001,\n",
       "  'lr_actor': 0.0001,\n",
       "  'eps': 1e-08,\n",
       "  'momentum': 0.9,\n",
       "  'betas': (0.9, 0.999),\n",
       "  'weight_decay': 0},\n",
       " 'train_steps': 100000,\n",
       " 'reward_clip': (-1.0, 1.0),\n",
       " 'test_steps': 1000,\n",
       " 'test_freq': 32000,\n",
       " 'log_freq': 10000,\n",
       " 'model_save_freq': 64000}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = make_config(\n",
    "        experiment_id=\"AC\",\n",
    "        basepath=\"/media/hemu/Data/madigan/experiments\",\n",
    "    \n",
    "    \n",
    "        transaction_cost_rel=0.02,\n",
    "    \n",
    "        test_steps=1_000,\n",
    "        nsteps=1_000_000,\n",
    "    \n",
    "#         data_source_type=\"Triangle\",\n",
    "#         generator_params={\n",
    "#         'freq':[2.],\n",
    "#         'mu':[0.6],\n",
    "#         'amp':[.5],\n",
    "#         'phase':[0.],\n",
    "#         'dX':0.1,\n",
    "#         \"noise\": 0.0},\n",
    "        assets=[\"sine1\"],\n",
    "        data_source_type=\"SineAdder\",\n",
    "        data_source_config={\n",
    "            'freq':[2.2, 4.1, 1., 3.],\n",
    "            'mu':[.6, 0.3, 2., 4.2],\n",
    "            'amp':[.5, 0.2, 0.4, 1.2],\n",
    "            'phase':[0., 1., 4., 0.],\n",
    "            'dX':0.01,\n",
    "            \"noise\": 0.0},\n",
    "#         assets=[\"OU1\"],\n",
    "#         data_source_type=\"OU\",\n",
    "#         data_source_config=dict(\n",
    "#             mean=[10.],\n",
    "#             theta=[.15],\n",
    "#             phi = [4.],\n",
    "#             noise_var = [.1]\n",
    "#         ),\n",
    "#         assets=[\"trend1\"],\n",
    "#         data_source_type=\"SimpleTrend\",\n",
    "#         data_source_config=dict(\n",
    "#             trend_prob=[.001],\n",
    "#             min_period=[500],\n",
    "#             max_period=[1500],\n",
    "#             noise = [.1],\n",
    "#             dY = [0.001],\n",
    "#             start = [5.0]),\n",
    "        preprocessor_type=\"RollerDiscrete\",\n",
    "        preprocessor_config=dict(\n",
    "#             timeframes = [64, 128, 512],\n",
    "            timeframes=[64],\n",
    "            window_length = 64,\n",
    "        ),\n",
    "    \n",
    "        agent_type = \"DQN\",\n",
    "        discrete_actions=True,\n",
    "        discrete_action_atoms=3,\n",
    "        double_dqn=True,\n",
    "        dueling=True,\n",
    "        iqn=True,\n",
    "        nTau1=32,\n",
    "        nTau2=8,\n",
    "        k_huber=1,\n",
    "        nstep_return = 5,\n",
    "        tau_soft_update=1e-4,\n",
    "        replay_size=100_000,\n",
    "        replay_min_size=50_000,\n",
    "        batch_size=34,\n",
    "        discount = 0.999,\n",
    "        lot_unit_value=10_000,\n",
    "        unit_size_proportion_avM=0.05,\n",
    "    \n",
    "        expl_eps_decay=0.999999,\n",
    "    \n",
    "        model_class=\"ConvNet\",\n",
    "        d_model = 1024,\n",
    "        lr=1e-5,\n",
    "\n",
    "    )\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make_env(config)\n",
    "\n",
    "# agent = make_agent(config)\n",
    "\n",
    "preprocessor = make_preprocessor(config)\n",
    "preprocessor.initialize_history(env)\n",
    "\n",
    "agent = ActorCritic_CNN(config, preprocessor.feature_output_shape, env, device=device)\n",
    "# agent = Actor_CNN(config, preprocessor.feature_output_shape, env, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_loop = iter(trainer(agent, env, preprocessor, config))\n",
    "   \n",
    "train_metrics=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40a76a948e474fdd94ff5efc9d20bf8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=500000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (154) must match the size of tensor b (1179) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-8f8545e2f3b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mtrain_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-38886861abe3>\u001b[0m in \u001b[0;36mtrainer\u001b[0;34m(agent, env, preprocessor, config, episode_length)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepisode_step\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mepisode_length\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0msarsd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepisode_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mtrain_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msarsd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mtrain_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'running_reward'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunning_reward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-d29e99626c07>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, sarsd)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mstate_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_state_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mstate_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_val_mem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0madv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcritic_target\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstate_val\u001b[0m \u001b[0;31m# aka td_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0mlogp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogp_mem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (154) must match the size of tensor b (1179) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "iterations = 500_000\n",
    "\n",
    "env.reset()\n",
    "for i in tqdm(range(iterations)):\n",
    "    metrics = next(train_loop)\n",
    "    if metrics is not None:\n",
    "        train_metrics.append(metrics)\n",
    "        \n",
    "agent.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize(10, 7.5)\n",
    "\n",
    "\n",
    "trn_metrics = reduce_train_metrics(list_2_dict(train_metrics), ['Qt', 'Gt'])\n",
    "\n",
    "plt.plot(trn_metrics['loss'], label='loss')\n",
    "plt.plot(trn_metrics['return'], label='return')\n",
    "# plt.plot(trn_metrics['td_error'], label='td_error')\n",
    "# plt.plot(trn_metrics['state_val'], label='state_val')\n",
    "# plt.plot(trn_metrics['Gt'], label='Gt')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from madigan.utils.plotting import plot_test_metrics\n",
    "figsize(15, 10)\n",
    "reset=True\n",
    "reset=False\n",
    "agent.model.eval()\n",
    "tst_metrics = test(agent, env, preprocessor, \n",
    "                   nsteps=1024, verbose=True, reset=reset, eps=0.)\n",
    "print(tst_metrics.keys())\n",
    "\n",
    "fig, ax = plot_test_metrics(tst_metrics, include=('equity', 'prices', 'cash', 'positions',\n",
    "                                                 'margin', 'transactions', 'positions', 'action_probs',\n",
    "                                                  'state_val'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(state.price)\n",
    "agent.get_policy(state).probs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "state = {'state_dict': agent.model_t.state_dict(),\n",
    "         'ntraining_steps': i, \n",
    "        'config': config}\n",
    "torch.save(state, 'sineadder_behaviour_good.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(agent.model_t.parameters())\n",
    "print(\"biases\", params[1])\n",
    "weights = params[0].detach().cpu().numpy()\n",
    "for i in range(0, 64):    \n",
    "    plt.plot(weights[i], label=str(i))\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "perfect_agent = PerfectAgent(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_metrics = test(perfect_agent, env, preprocessor, verbose=True)\n",
    "print(tst_metrics.keys())\n",
    "fig, ax = plot_test_metrics(tst_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perfect_agent.get_qvals(preprocessor.current_data()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor.current_data().price.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
