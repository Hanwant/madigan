{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from madigan.fleet.net.utils import calc_pad_to_conserve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DilConvLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    1D Causal Convolution using small dilated kernels\n",
    "    Contains residual connection as well as skip connection to output\n",
    "    \"\"\"\n",
    "    def __init__(self, channels_in, channels_out, kernel, stride, dilation,\n",
    "                 dropout):\n",
    "        super().__init__()\n",
    "        self.c_in = channels_in\n",
    "        self.c_out = channels_out\n",
    "        self.kernel = kernel\n",
    "        self.dilation = dilation\n",
    "        self.stride = stride\n",
    "        self.dropout = dropout\n",
    "#         self.output_shape = output_shape\n",
    "        self.act_fn = nn.GELU()\n",
    "        self.conv_project = nn.Conv1d(channels_in, channels_out, kernel, \n",
    "                                       dilation=dilation,\n",
    "                                      stride=stride, bias=False)\n",
    "        padding = (dilation*(kernel - 1), 0)\n",
    "        self.causal_padding_layer = nn.ReplicationPad1d(padding)\n",
    "        self.conv_embed = nn.Sequential(self.conv_project, self.causal_padding_layer,\n",
    "                                       self.act_fn)\n",
    "        self.conv_compress = nn.Conv1d(channels_out, 1, kernel_size=1, \n",
    "                                       bias=False)\n",
    "        self.skip_conv = nn.Conv1d(channels_out, 1, kernel_size=1,\n",
    "                                   bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        latent = self.conv_embed(x)\n",
    "#         import ipdb; ipdb.set_trace()\n",
    "        res = x + self.conv_compress(latent)\n",
    "        skip_connection = self.dropout(self.skip_conv(latent))\n",
    "        return res, skip_connection\n",
    "    \n",
    "class SeriesNet(nn.Module):\n",
    "    def __init__(self, input_length, input_dim, output_length, channel_dims, kernels,\n",
    "                 dilations, strides, dropouts):\n",
    "        super().__init__()\n",
    "        assert(len(channel_dims) == len(kernels) == len(dilations)\n",
    "              == len(strides) == len(dropouts)), \\\n",
    "               \"layer hyperparams must be same length - n_layers\"\n",
    "        self.output_act_fn = nn.ReLU()\n",
    "        self.layers = []\n",
    "        for i in range(len(kernels)):\n",
    "            self.layers.append(DilConvLayer(1,\n",
    "                                       channel_dims[i], kernels[i],\n",
    "                                       strides[i], dilations[i], \n",
    "                                       dropouts[i]))\n",
    "        self.output_compression = nn.Conv1d(channel_dims[-1], out_channels=1,\n",
    "                                            kernel_size=1, bias=False)\n",
    "        self.output_layer = nn.Linear(input_length, output_length)\n",
    "        self.apply(self.init)\n",
    "        \n",
    "    def init(self, m):\n",
    "        if isinstance(m, nn.Conv1d):\n",
    "            nn.init.normal_(m.weight, mean=0., std=0.05)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x, out = self.layers[0](x)\n",
    "        for layer in self.layers[1:]:\n",
    "            x, skip_out = layer(x)\n",
    "            out += skip_out\n",
    "        out = self.output_act_fn(out)\n",
    "        out = self.output_layer(out)\n",
    "        return out.view(out.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_len = 108\n",
    "input_dim = 1\n",
    "output_len = 1\n",
    "x = torch.randn(1, input_dim, input_len)\n",
    "\n",
    "model = SeriesNet(input_len, input_dim, output_len, \n",
    "                 [32, 32, 32, 32, 32, 32, 32],\n",
    "                 [2, 2, 2, 2, 2, 2, 2],\n",
    "                 [1, 2, 4, 8, 16, 32, 64],\n",
    "                 [1]*7,\n",
    "                 [0., 0., 0., 0., 0., 0.8, 0.8])\n",
    "model(x).shape\n",
    "# model.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('madigan')",
   "language": "python",
   "name": "python37764bitmadiganc2cb1639caeb405b9f43012997461129"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
